
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>word embeddings - Sebastian Ruder</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" type="text/css" href="../../assets/built/screen.css?v=598e4ecdd9">

    <link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon">
    <link rel="canonical" href="http://ruder.io/tag/word-embeddings/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="Sebastian Ruder">
    <meta property="og:type" content="website">
    <meta property="og:title" content="word embeddings - Sebastian Ruder">
    <meta property="og:url" content="http://ruder.io/tag/word-embeddings/">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="word embeddings - Sebastian Ruder">
    <meta name="twitter:url" content="http://ruder.io/tag/word-embeddings/">
    <meta name="twitter:site" content="@seb_ruder">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Series",
    "publisher": {
        "@type": "Organization",
        "name": "Sebastian Ruder",
        "logo": {
            "@type": "ImageObject",
            "url": "http://ruder.io/favicon.ico",
            "width": 60,
            "height": 60
        }
    },
    "url": "http://ruder.io/tag/word-embeddings/",
    "name": "word embeddings",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://ruder.io/"
    }
}
    </script>

    <script src="../../public/ghost-sdk.js?v=598e4ecdd9"></script>
<script>
ghost.init({
	clientId: "ghost-frontend",
	clientSecret: "bc1baff4b81d"
});
</script>
    <meta name="generator" content="Ghost 2.11">
    <link rel="alternate" type="application/rss+xml" title="Sebastian Ruder" href="http://ruder.io/rss/">
    <script>
var profile_title = 'Sebastian Ruder';
</script>
<script>
var disqus_shortname = 'sebastianruder';
</script>
<script>
var profile_resume ='NLP PhD student';
</script>
<script>
var ga_id = 'UA-60512592-1';
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]],
        processEscapes: true
    }
});
</script>

</head>
<body class="tag-template tag-word-embeddings">

    <div class="site-wrapper">

        


<header class="site-header outer no-image">

 
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
                <a class="site-nav-logo" href="http://ruder.io">Sebastian Ruder</a>
            <ul class="nav" role="menu">
    <li class="nav-about" role="menuitem"><a href="http://ruder.io/about/">About</a></li>
    <li class="nav-tags" role="menuitem"><a href="http://ruder.io/tags/">Tags</a></li>
    <li class="nav-papers" role="menuitem"><a href="http://ruder.io/publications/">Papers</a></li>
    <li class="nav-talks" role="menuitem"><a href="http://ruder.io/talks/">Talks</a></li>
    <li class="nav-news" role="menuitem"><a href="http://ruder.io/news/">News</a></li>
    <li class="nav-faq" role="menuitem"><a href="http://ruder.io/faq/">FAQ</a></li>
    <li class="nav-nlp-news" role="menuitem"><a href="http://ruder.io/nlp-news/">NLP News</a></li>
    <li class="nav-nlp-progress" role="menuitem"><a href="https://nlpprogress.com/">NLP Progress</a></li>
</ul>

    </div>
    <div class="site-nav-right">
        <div class="social-links">
                <a class="social-link social-link-tw" href="https://twitter.com/seb_ruder" title="Twitter" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"></path></svg>
</a>
        </div>
            <a class="rss-button" href="http://ruder.io/rss/index.rss" title="RSS" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><circle cx="6.18" cy="17.82" r="2.18"></circle><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"></path></svg>
</a>
    </div>
</nav>
        <div class="site-header-content">
            <h1 class="site-title">word embeddings</h1>
            <h2 class="site-description">
                    Posts about different aspects of word embeddings.
            </h2>
        </div>
    </div>
</header>

<main id="site-main" class="site-main outer">
    <div class="inner">
        <div class="post-feed">
                <article class="post-card post tag-events tag-natural-language-processing tag-transfer-learning tag-word-embeddings ">

    <a class="post-card-image-link" href="../../aaai-2019-highlights/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2019/02/aaai_reception-1.jpg 300w,
                    http://ruder.io/content/images/size/w600/2019/02/aaai_reception-1.jpg 600w,
                    http://ruder.io/content/images/size/w1000/2019/02/aaai_reception-1.jpg 1000w,
                    http://ruder.io/content/images/size/w2000/2019/02/aaai_reception-1.jpg 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2019/02/aaai_reception-1.jpg" alt="AAAI 2019 Highlights: Dialogue, reproducibility, and more">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../aaai-2019-highlights/">

            <header class="post-card-header">
                    <span class="post-card-tags">events</span>
                <h2 class="post-card-title">AAAI 2019 Highlights: Dialogue, reproducibility, and more</h2>
            </header>

            <section class="post-card-excerpt">
                <p>This post discusses highlights of AAAI 2019. It covers dialogue, reproducibility, question answering, the Oxford style debate, invited talks, and a diverse set of research papers.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">11 min read</span>

        </footer>

    </div>

</article>
                <article class="post-card post tag-events tag-transfer-learning tag-cross-lingual tag-word-embeddings tag-language-models tag-natural-language-processing ">

    <a class="post-card-image-link" href="../../emnlp-2018-highlights/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2018/11/emnlp_conference_garden_view.jpg 300w,
                    http://ruder.io/content/images/size/w600/2018/11/emnlp_conference_garden_view.jpg 600w,
                    http://ruder.io/content/images/size/w1000/2018/11/emnlp_conference_garden_view.jpg 1000w,
                    http://ruder.io/content/images/size/w2000/2018/11/emnlp_conference_garden_view.jpg 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2018/11/emnlp_conference_garden_view.jpg" alt="EMNLP 2018 Highlights: Inductive bias, cross-lingual learning, and more">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../emnlp-2018-highlights/">

            <header class="post-card-header">
                    <span class="post-card-tags">events</span>
                <h2 class="post-card-title">EMNLP 2018 Highlights: Inductive bias, cross-lingual learning, and more</h2>
            </header>

            <section class="post-card-excerpt">
                <p>This post discusses highlights of EMNLP 2018. It focuses on talks and papers dealing with inductive bias, cross-lingual learning, word embeddings, latent variable models, language models, and datasets.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">11 min read</span>

        </footer>

    </div>

</article>
                <article class="post-card post tag-language-models tag-natural-language-processing tag-word-embeddings tag-multi-task-learning tag-transfer-learning ">

    <a class="post-card-image-link" href="../../a-review-of-the-recent-history-of-nlp/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2018/10/neural_history_of_nlp_image.png 300w,
                    http://ruder.io/content/images/size/w600/2018/10/neural_history_of_nlp_image.png 600w,
                    http://ruder.io/content/images/size/w1000/2018/10/neural_history_of_nlp_image.png 1000w,
                    http://ruder.io/content/images/size/w2000/2018/10/neural_history_of_nlp_image.png 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2018/10/neural_history_of_nlp_image.png" alt="A Review of the Neural History of Natural Language Processing">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../a-review-of-the-recent-history-of-nlp/">

            <header class="post-card-header">
                    <span class="post-card-tags">language models</span>
                <h2 class="post-card-title">A Review of the Neural History of Natural Language Processing</h2>
            </header>

            <section class="post-card-excerpt">
                <p>This post expands on the Frontiers of Natural Language Processing session organized at the Deep Learning Indaba 2018. It discusses major recent advances in NLP focusing on neural network-based methods.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">29 min read</span>

        </footer>

    </div>

</article>
                <article class="post-card post tag-word-embeddings tag-natural-language-processing tag-cross-lingual ">

    <a class="post-card-image-link" href="../../word-embeddings-2017/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2017/10/semantic_change.png 300w,
                    http://ruder.io/content/images/size/w600/2017/10/semantic_change.png 600w,
                    http://ruder.io/content/images/size/w1000/2017/10/semantic_change.png 1000w,
                    http://ruder.io/content/images/size/w2000/2017/10/semantic_change.png 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2017/10/semantic_change.png" alt="Word embeddings in 2017: Trends and future directions">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../word-embeddings-2017/">

            <header class="post-card-header">
                    <span class="post-card-tags">word embeddings</span>
                <h2 class="post-card-title">Word embeddings in 2017: Trends and future directions</h2>
            </header>

            <section class="post-card-excerpt">
                <p>Word embeddings are an integral part of current NLP models, but approaches  that supersede the original word2vec have not been proposed. This post focuses on the deficiencies of word embeddings and how recent approaches have tried to resolve them.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">17 min read</span>

        </footer>

    </div>

</article>
                <article class="post-card post tag-natural-language-processing tag-word-embeddings tag-cross-lingual tag-events ">

    <a class="post-card-image-link" href="../../highlights-emnlp-2017/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2017/09/emnlp_landscape.jpg 300w,
                    http://ruder.io/content/images/size/w600/2017/09/emnlp_landscape.jpg 600w,
                    http://ruder.io/content/images/size/w1000/2017/09/emnlp_landscape.jpg 1000w,
                    http://ruder.io/content/images/size/w2000/2017/09/emnlp_landscape.jpg 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2017/09/emnlp_landscape.jpg" alt="Highlights of EMNLP 2017: Exciting datasets, return of the clusters, and more">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../highlights-emnlp-2017/">

            <header class="post-card-header">
                    <span class="post-card-tags">natural language processing</span>
                <h2 class="post-card-title">Highlights of EMNLP 2017: Exciting datasets, return of the clusters, and more</h2>
            </header>

            <section class="post-card-excerpt">
                <p>This post discusses highlights of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017). These include exciting datasets, new cluster-based methods, distant supervision, data selection, character-level models, and many more.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">10 min read</span>

        </footer>

    </div>

</article>
                <article class="post-card post tag-cross-lingual tag-word-embeddings tag-natural-language-processing ">

    <a class="post-card-image-link" href="../../cross-lingual-embeddings/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2016/10/zou_et_al_2013.png 300w,
                    http://ruder.io/content/images/size/w600/2016/10/zou_et_al_2013.png 600w,
                    http://ruder.io/content/images/size/w1000/2016/10/zou_et_al_2013.png 1000w,
                    http://ruder.io/content/images/size/w2000/2016/10/zou_et_al_2013.png 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2016/10/zou_et_al_2013.png" alt="A survey of cross-lingual word embedding models">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../cross-lingual-embeddings/">

            <header class="post-card-header">
                    <span class="post-card-tags">cross-lingual</span>
                <h2 class="post-card-title">A survey of cross-lingual word embedding models</h2>
            </header>

            <section class="post-card-excerpt">
                <p>Monolingual word embeddings are pervasive in NLP. To represent meaning and transfer knowledge across different languages, cross-lingual word embeddings can be used. Such methods learn representations of words in a joint embedding space.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">41 min read</span>

        </footer>

    </div>

</article>
                <article class="post-card post tag-natural-language-processing tag-word-embeddings tag-reinforcement-learning tag-events ">

    <a class="post-card-image-link" href="../../emnlp-2016-highlights/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2016/11/emnlp_cover_image.jpg 300w,
                    http://ruder.io/content/images/size/w600/2016/11/emnlp_cover_image.jpg 600w,
                    http://ruder.io/content/images/size/w1000/2016/11/emnlp_cover_image.jpg 1000w,
                    http://ruder.io/content/images/size/w2000/2016/11/emnlp_cover_image.jpg 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2016/11/emnlp_cover_image.jpg" alt="Highlights of EMNLP 2016: Dialogue, deep learning, and more">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../emnlp-2016-highlights/">

            <header class="post-card-header">
                    <span class="post-card-tags">natural language processing</span>
                <h2 class="post-card-title">Highlights of EMNLP 2016: Dialogue, deep learning, and more</h2>
            </header>

            <section class="post-card-excerpt">
                <p>This post discusses highlights of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP 2016). These include work on reinforcement learning, dialogue, sequence-to-sequence models, semantic parsing, natural language generation, and many more.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">4 min read</span>

        </footer>

    </div>

</article>
                <article class="post-card post tag-word-embeddings tag-natural-language-processing ">

    <a class="post-card-image-link" href="../../secret-word2vec/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2016/09/merge_from_ofoct--2-.jpg 300w,
                    http://ruder.io/content/images/size/w600/2016/09/merge_from_ofoct--2-.jpg 600w,
                    http://ruder.io/content/images/size/w1000/2016/09/merge_from_ofoct--2-.jpg 1000w,
                    http://ruder.io/content/images/size/w2000/2016/09/merge_from_ofoct--2-.jpg 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2016/09/merge_from_ofoct--2-.jpg" alt="On word embeddings - Part 3: The secret ingredients of word2vec">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../secret-word2vec/">

            <header class="post-card-header">
                    <span class="post-card-tags">word embeddings</span>
                <h2 class="post-card-title">On word embeddings - Part 3: The secret ingredients of word2vec</h2>
            </header>

            <section class="post-card-excerpt">
                <p>Word2vec is a pervasive tool for learning word embeddings. Its success, however, is mostly due to particular architecture choices. Transferring these choices to traditional distributional methods makes them competitive with popular word embedding methods.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">9 min read</span>

        </footer>

    </div>

</article>
                <article class="post-card post tag-word-embeddings tag-natural-language-processing tag-language-models ">

    <a class="post-card-image-link" href="../../word-embeddings-softmax/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2016/06/softmax_classifier.png 300w,
                    http://ruder.io/content/images/size/w600/2016/06/softmax_classifier.png 600w,
                    http://ruder.io/content/images/size/w1000/2016/06/softmax_classifier.png 1000w,
                    http://ruder.io/content/images/size/w2000/2016/06/softmax_classifier.png 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2016/06/softmax_classifier.png" alt="On word embeddings - Part 2: Approximating the Softmax">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../word-embeddings-softmax/">

            <header class="post-card-header">
                    <span class="post-card-tags">word embeddings</span>
                <h2 class="post-card-title">On word embeddings - Part 2: Approximating the Softmax</h2>
            </header>

            <section class="post-card-excerpt">
                <p>The softmax layer is a core part of many current neural network architectures. When the number of output classes is very large, such as in the case of language modelling, computing the softmax becomes very expensive. This post explores approximations to make the computation more efficient.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">33 min read</span>

        </footer>

    </div>

</article>
                <article class="post-card post tag-word-embeddings tag-natural-language-processing tag-language-models ">

    <a class="post-card-image-link" href="../../word-embeddings-1/">
        <img class="post-card-image" srcset="http://ruder.io/content/images/size/w300/2016/04/word_embeddings_colah.png 300w,
                    http://ruder.io/content/images/size/w600/2016/04/word_embeddings_colah.png 600w,
                    http://ruder.io/content/images/size/w1000/2016/04/word_embeddings_colah.png 1000w,
                    http://ruder.io/content/images/size/w2000/2016/04/word_embeddings_colah.png 2000w" sizes="(max-width: 1000px) 400px, 700px" src="http://ruder.io/content/images/size/w600/2016/04/word_embeddings_colah.png" alt="On word embeddings - Part 1">
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../../word-embeddings-1/">

            <header class="post-card-header">
                    <span class="post-card-tags">word embeddings</span>
                <h2 class="post-card-title">On word embeddings - Part 1</h2>
            </header>

            <section class="post-card-excerpt">
                <p>Word embeddings popularized by word2vec are pervasive in current NLP applications. The history of word embeddings, however, goes back a lot further. This post explores the history of word embeddings in the context of language modelling.</p>
            </section>

        </a>

        <footer class="post-card-meta">

            <ul class="author-list">
                <li class="author-list-item">

                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>

                        <a href="../../author/sebastian/" class="static-avatar">
                            <img class="author-profile-image" src="http://ruder.io/content/images/size/w100/2018/10/aylien_profile_photo.jpg" alt="Sebastian Ruder">
                        </a>
                </li>
            </ul>

            <span class="reading-time">15 min read</span>

        </footer>

    </div>

</article>
        </div>
    </div>
</main>


        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="http://ruder.io">Sebastian Ruder</a> Â© 2019</section>
                <nav class="site-footer-nav">
                    <a href="http://ruder.io">Latest Posts</a>
                    
                    <a href="https://twitter.com/seb_ruder" target="_blank" rel="noopener">Twitter</a>
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>


    <script>
        var images = document.querySelectorAll('.kg-gallery-image img');
        images.forEach(function (image) {
            var container = image.closest('.kg-gallery-image');
            var width = image.attributes.width.value;
            var height = image.attributes.height.value;
            var ratio = width / height;
            container.style.flex = ratio + ' 1 0%';
        })
    </script>


    <script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="../../assets/built/jquery.fitvids.js?v=598e4ecdd9"></script>

    <script src="../../assets/built/infinitescroll.js?v=598e4ecdd9"></script>

    

    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.1.6/zepto.min.js"></script>
<script>jQuery = Zepto</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/plugins/line-numbers/prism-line-numbers.min.js"></script>
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/plugins/line-numbers/prism-line-numbers.min.css">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism-coy.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-python.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-60512592-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-60512592-1');
</script>

</body>

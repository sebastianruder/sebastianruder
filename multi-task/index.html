<!DOCTYPE html>
<html lang="en">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>An Overview of Multi-Task Learning for Deep Learning</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="../assets/built/screen.css?v=858352cb6c" />

    <meta name="description" content="This blog post gives an overview of multi-task learning in deep neural networks. It discusses existing approaches as well as recent advances." />
    <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon" />
    <link rel="canonical" href="https://ruder.io/multi-task/" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <link rel="amphtml" href="https://ruder.io/multi-task/amp/" />
    
    <meta property="og:site_name" content="Sebastian Ruder" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="An Overview of Multi-Task Learning for Deep Learning" />
    <meta property="og:description" content="Multi-task learning is becoming more and more popular. This post gives a general overview of the current state of multi-task learning. In particular, it provides context for current neural network-based methods by discussing the extensive multi-task learning literature." />
    <meta property="og:url" content="https://ruder.io/multi-task/" />
    <meta property="og:image" content="https://ruder.io/content/images/2017/05/mtl_images-002-2.png" />
    <meta property="article:published_time" content="2017-05-29T13:00:00.000Z" />
    <meta property="article:modified_time" content="2018-10-24T13:22:42.000Z" />
    <meta property="article:tag" content="multi-task learning" />
    <meta property="article:tag" content="transfer learning" />
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="An Overview of Multi-Task Learning for Deep Learning" />
    <meta name="twitter:description" content="Multi-task learning is becoming more and more popular. This post gives a general overview of the current state of multi-task learning. In particular, it provides context for current neural network-based methods by discussing the extensive multi-task learning literature." />
    <meta name="twitter:url" content="https://ruder.io/multi-task/" />
    <meta name="twitter:image" content="https://ruder.io/content/images/2017/05/mtl_images-002-2.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Sebastian Ruder" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="multi-task learning, transfer learning" />
    <meta name="twitter:site" content="@seb_ruder" />
    <meta property="og:image:width" content="1005" />
    <meta property="og:image:height" content="385" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Sebastian Ruder",
        "url": "https://ruder.io/",
        "logo": {
            "@type": "ImageObject",
            "url": {
                "@type": "ImageObject",
                "url": "https://ruder.io/favicon.ico",
                "width": 48,
                "height": 48
            }
        }
    },
    "author": {
        "@type": "Person",
        "name": "Sebastian Ruder",
        "image": {
            "@type": "ImageObject",
            "url": "https://ruder.io/content/images/2019/02/new_profile_photo_square-1.jpg",
            "width": 2000,
            "height": 2000
        },
        "url": "https://ruder.io/author/sebastian/",
        "sameAs": []
    },
    "headline": "An Overview of Multi-Task Learning for Deep Learning",
    "url": "https://ruder.io/multi-task/",
    "datePublished": "2017-05-29T13:00:00.000Z",
    "dateModified": "2018-10-24T13:22:42.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://ruder.io/content/images/2017/05/mtl_images-002-2.png",
        "width": 1005,
        "height": 385
    },
    "keywords": "multi-task learning, transfer learning",
    "description": "Multi-task learning is becoming more and more popular. This post gives a general overview of the current state of multi-task learning. In particular, it provides context for current neural network-based methods by discussing the extensive multi-task learning literature.",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://ruder.io/"
    }
}
    </script>

    <meta name="generator" content="Ghost 3.11" />
    <link rel="alternate" type="application/rss+xml" title="Sebastian Ruder" href="https://ruder.io/rss/" />
    <script>
var profile_title = 'Sebastian Ruder';
</script>
<script>
var disqus_shortname = 'sebastianruder';
</script>
<script>
var profile_resume ='NLP PhD student';
</script>
<script>
var ga_id = 'UA-60512592-1';
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]],
        processEscapes: true
    }
});
</script>

</head>
<body class="post-template tag-multi-task-learning tag-transfer-learning">

    <div class="site-wrapper">

        

<header class="site-header">
    <div class="outer site-nav-main">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left-wrapper">
        <div class="site-nav-left">
                <a class="site-nav-logo" href="https://ruder.io">Sebastian Ruder</a>
            <div class="site-nav-content">
                    <ul class="nav" role="menu">
    <li class="nav-about" role="menuitem"><a href="https://ruder.io/about/">About</a></li>
    <li class="nav-tags" role="menuitem"><a href="https://ruder.io/tags/">Tags</a></li>
    <li class="nav-papers" role="menuitem"><a href="https://ruder.io/publications/">Papers</a></li>
    <li class="nav-talks" role="menuitem"><a href="https://ruder.io/talks/">Talks</a></li>
    <li class="nav-news" role="menuitem"><a href="https://ruder.io/news/">News</a></li>
    <li class="nav-faq" role="menuitem"><a href="https://ruder.io/faq/">FAQ</a></li>
    <li class="nav-sign-up-for-nlp-news" role="menuitem"><a href="https://ruder.io/nlp-news/">Sign up for NLP News</a></li>
    <li class="nav-nlp-progress" role="menuitem"><a href="https://nlpprogress.com/">NLP Progress</a></li>
    <li class="nav-media" role="menuitem"><a href="https://ruder.io/media/">Media</a></li>
    <li class="nav-contact" role="menuitem"><a href="https://ruder.io/contact/">Contact</a></li>
</ul>

                    <span class="nav-post-title dash">An Overview of Multi-Task Learning in Deep Neural Networks</span>
            </div>
        </div>
    </div>
    <div class="site-nav-right">
            <div class="social-links">
                    <a class="social-link social-link-tw" href="https://twitter.com/seb_ruder" title="Twitter" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            </div>
                <a class="rss-button" href="https://ruder.io/rss/index.rss" title="RSS" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
</a>

    </div>
</nav>
    </div>
</div></header>


<main id="site-main" class="site-main outer">
    <div class="inner">

        <article class="post-full post tag-multi-task-learning tag-transfer-learning ">

            <header class="post-full-header">

                <section class="post-full-tags">
                    <a href="../tag/multi-task-learning/index.html">multi-task learning</a>
                </section>

                <h1 class="post-full-title">An Overview of Multi-Task Learning in Deep Neural Networks</h1>

                <p class="post-full-custom-excerpt">Multi-task learning is becoming more and more popular. This post gives a general overview of the current state of multi-task learning. In particular, it provides context for current neural network-based methods by discussing the extensive multi-task learning literature.</p>

                <div class="post-full-byline">

                    <section class="post-full-byline-content">

                        <ul class="author-list">
                            <li class="author-list-item">

                                <div class="author-card">
                                    <img class="author-profile-image" src="../content/images/size/w100/2019/02/new_profile_photo_square-1.jpg" alt="Sebastian Ruder" />
                                    <div class="author-info">
                                        <h2>Sebastian Ruder</h2>
                                        <p>Read <a href="../author/sebastian/index.html">more posts</a> by this author.</p>
                                    </div>
                                </div>

                                <a href="../author/sebastian/index.html" class="author-avatar">
                                    <img class="author-profile-image" src="../content/images/size/w100/2019/02/new_profile_photo_square-1.jpg" alt="Sebastian Ruder" />
                                </a>

                            </li>
                        </ul>

                        <section class="post-full-byline-meta">
                            <h4 class="author-name"><a href="../author/sebastian/index.html">Sebastian Ruder</a></h4>
                            <div class="byline-meta-content">
                                <time class="byline-meta-date" datetime="2017-05-29">29 May 2017</time>
                                <span class="byline-reading-time"><span class="bull">&bull;</span> 29 min read</span>
                            </div>
                        </section>

                    </section>


                </div>
            </header>

            <figure class="post-full-image">
                <img
                    srcset="../content/images/size/w300/2017/05/mtl_images-002-2.png 300w,
                           ../content/images/size/w600/2017/05/mtl_images-002-2.png 600w,
                          ../content/images/size/w1000/2017/05/mtl_images-002-2.png 1000w,
                         ../content/images/size/w2000/2017/05/mtl_images-002-2.png 2000w"
                    sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px"
                    src="../content/images/size/w2000/2017/05/mtl_images-002-2.png"
                    alt="An Overview of Multi-Task Learning in Deep Neural Networks"
                />
            </figure>

            <section class="post-full-content">
                <div class="post-content">
                    <!--kg-card-begin: markdown--><p>This post gives a general overview of the current state of multi-task learning.</p>
<p>Note: If you are looking for a review paper, this blog post is also available as an <a href="https://arxiv.org/abs/1706.05098">article on arXiv</a>.</p>
<p>Table of contents:</p>
<ul>
<li><a href="index.html#introduction">Introduction</a></li>
<li><a href="index.html#motivation">Motivation</a></li>
<li><a href="index.html#twomtlmethodsfordeeplearning">Two MTL methods for Deep Learning</a>
<ul>
<li><a href="index.html#hardparametersharing">Hard parameter sharing</a></li>
<li><a href="index.html#softparametersharing">Soft parameter sharing</a></li>
</ul>
</li>
<li><a href="index.html#whydoesmtlwork">Why does MTL work?</a>
<ul>
<li><a href="index.html#implicitdataaugmentation">Implicit data augmentation</a></li>
<li><a href="index.html#attentionfocusing">Attention focusing</a></li>
<li><a href="index.html#eavesdropping">Eavesdropping</a></li>
<li><a href="index.html#representationbias">Representation bias</a></li>
<li><a href="index.html#regularization">Regularization</a></li>
</ul>
</li>
<li><a href="index.html#mtlinnonneuralmodels">MTL in non-neural models</a>
<ul>
<li><a href="index.html#blocksparseregularization">Block-sparse regularization</a></li>
<li><a href="index.html#learningtaskrelationships">Learning task relationships</a></li>
</ul>
</li>
<li><a href="index.html#recentworkonmtlfordeeplearning">Recent work on MTL for Deep Learning</a>
<ul>
<li><a href="index.html#deeprelationshipnetworks">Deep Relationship Networks</a></li>
<li><a href="index.html#fullyadaptivefeaturesharing">Fully-Adaptive Feature Sharing</a></li>
<li><a href="index.html#crossstitchnetworks">Cross-stitch Networks</a></li>
<li><a href="index.html#lowsupervision">Low supervision</a></li>
<li><a href="index.html#ajointmanytaskmodel">A Joint Many-Task model</a></li>
<li><a href="index.html#weightinglosseswithuncertainty">Weighting losses with uncertainty</a></li>
<li><a href="index.html#tensorfactorisationformtl">Tensor factorisation for MTL</a></li>
<li><a href="index.html#sluicenetworks">Sluice Networks</a></li>
<li><a href="index.html#whatshouldishareinmymodel">What should I share in my model?</a></li>
</ul>
</li>
<li><a href="index.html#auxiliarytasks">Auxiliary tasks</a>
<ul>
<li><a href="index.html#relatedtask">Related task</a></li>
<li><a href="index.html#adversarial">Adversarial</a></li>
<li><a href="index.html#hints">Hints</a></li>
<li><a href="index.html#focusingattention">Focusing attention</a></li>
<li><a href="index.html#quantizationsmoothing">Quantization smoothing</a></li>
<li><a href="index.html#predictinginputs">Predicting inputs</a></li>
<li><a href="index.html#usingthefuturetopredictthepresent">Using the future to predict the present</a></li>
<li><a href="index.html#representationlearning">Representation learning</a></li>
<li><a href="index.html#whatauxiliarytasksarehelpful">What auxiliary tasks are helpful?</a></li>
</ul>
</li>
<li><a href="index.html#conclusion">Conclusion</a></li>
</ul>
<h1 id="introduction">Introduction</h1>
<p>In Machine Learning (ML), we typically care about optimizing for a particular metric, whether this is a score on a certain benchmark or a business KPI. In order to do this, we generally train a single model or an ensemble of models to perform our desired task. We then fine-tune and tweak these models until their performance no longer increases. While we can generally achieve acceptable performance this way, by being laser-focused on our single task, we ignore information that might help us do even better on the metric we care about. Specifically, this information comes from the training signals of related tasks. By sharing representations between related tasks, we can enable our model to generalize better on our original task. This approach is called Multi-Task Learning (MTL) and will be the topic of this blog post.</p>
<p>Multi-task learning has been used successfully across all applications of machine learning, from natural language processing <sup class="footnote-ref"><a href="index.html#fn1" id="fnref1">[1]</a></sup> and speech recognition <sup class="footnote-ref"><a href="index.html#fn2" id="fnref2">[2]</a></sup> to computer vision <sup class="footnote-ref"><a href="index.html#fn3" id="fnref3">[3]</a></sup> and drug discovery <sup class="footnote-ref"><a href="index.html#fn4" id="fnref4">[4]</a></sup>. MTL comes in many guises: joint learning, learning to learn, and learning with auxiliary tasks are only some names that have been used to refer to it. Generally, as soon as you find yourself optimizing more than one loss function, you are effectively doing multi-task learning (in contrast to single-task learning). In those scenarios, it helps to think about what you are trying to do explicitly in terms of MTL and to draw insights from it.</p>
<p>Even if you're only optimizing one loss as is the typical case, chances are there is an auxiliary task that will help you improve upon your main task. Rich Caruana <sup class="footnote-ref"><a href="index.html#fn5" id="fnref5">[5]</a></sup> summarizes the goal of MTL succinctly: &quot;MTL improves generalization by leveraging the domain-specific information contained in the training signals of related tasks&quot;.</p>
<p>Over the course of this blog post, I will try to give a general overview of the current state of multi-task learning, in particular when it comes to MTL with deep neural networks. I will first motivate MTL from different perspectives. I will then introduce the two most frequently employed methods for MTL in Deep Learning. Subsequently, I will describe mechanisms that together illustrate why MTL works in practice. Before looking at more advanced neural network-based MTL methods, I will provide some context by discussing the literature in MTL. I will then introduce some more powerful recently proposed methods for MTL in deep neural networks. Finally, I will talk about commonly used types of auxiliary tasks and discuss what makes a good auxiliary task for MTL.</p>
<h1 id="motivation">Motivation</h1>
<p>We can motivate multi-task learning in different ways: Biologically, we can see multi-task learning as being inspired by human learning. For learning new tasks, we often apply the knowledge we have acquired by learning related tasks. For instance, a baby first learns to recognize faces and can then apply this knowledge to recognize other objects.</p>
<p>From a pedagogical perspective, we often learn tasks first that provide us with the necessary skills to master more complex techniques. This is true for learning the proper way of <a href="https://www.youtube.com/watch?v=NFPPrhxPFR4">falling in martial arts, e.g. Judo</a> as much as learning to program.</p>
<p>Taking an example out of pop culture, we can also consider <em>The Karate Kid</em> (1984) (thanks to <a href="http://m-mitchell.com/publications/multitask-blurb.html">Margaret Mitchell</a> and <a href="https://twitter.com/mmitchell_ai/status/849596878694096896">Adrian Benton</a> for the inspiration). In the movie, <em>sensei</em> Mr Miyagi teaches the karate kid seemingly unrelated tasks such as sanding the floor and waxing a car. In hindsight, these, however, turn out to equip him with invaluable skills that are <a href="https://www.youtube.com/embed/DsLk6hVBE6Y">relevant for learning karate</a>.</p>
<p>Finally, we can motivate multi-task learning from a machine learning point of view: We can view multi-task learning as a form of inductive transfer. Inductive transfer can help improve a model by introducing an inductive bias, which causes a model to prefer some hypotheses over others. For instance, a common form of inductive bias is \(\ell_1\) regularization, which leads to a preference for sparse solutions. In the case of MTL, the inductive bias is provided by the auxiliary tasks, which cause the model to prefer hypotheses that explain more than one task. As we will see shortly, this generally leads to solutions that generalize better.</p>
<h1 id="twomtlmethodsfordeeplearning">Two MTL methods for Deep Learning</h1>
<p>So far, we have focused on theoretical motivations for MTL. To make the ideas of MTL more concrete, we will now look at the two most commonly used ways to perform multi-task learning in deep neural networks. In the context of Deep Learning, multi-task learning is typically done with either <em>hard</em> or <em>soft parameter sharing</em> of hidden layers.</p>
<h2 id="hardparametersharing">Hard parameter sharing</h2>
<p>Hard parameter sharing is the most commonly used approach to MTL in neural networks and goes back to <sup class="footnote-ref"><a href="index.html#fn6" id="fnref6">[6]</a></sup>. It is generally applied by sharing the hidden layers between all tasks, while keeping several task-specific output layers.</p>
<figure>
      <img src="https://ruder.io/content/images/2017/05/mtl_images-001-2.png" style="width: 50%" title="Hard parameter sharing">
<figcaption>Figure 1: Hard parameter sharing for multi-task learning in deep neural networks</figcaption>
</figure>
<p>Hard parameter sharing greatly reduces the risk of overfitting. In fact, <sup class="footnote-ref"><a href="index.html#fn7" id="fnref7">[7]</a></sup> showed that the risk of overfitting the shared parameters is an order N -- where N is the number of tasks -- smaller than overfitting the task-specific parameters, i.e. the output layers. This makes sense intuitively: The more tasks we are learning simultaneously, the more our model has to find a representation that captures all of the tasks and the less is our chance of overfitting on our original task.</p>
<h2 id="softparametersharing">Soft parameter sharing</h2>
<p>In soft parameter sharing on the other hand, each task has its own model with its own parameters. The distance between the parameters of the model is then regularized in order to encourage the parameters to be similar. <sup class="footnote-ref"><a href="index.html#fn8" id="fnref8">[8]</a></sup> for instance use the \(\ell_2\) norm for regularization, while <sup class="footnote-ref"><a href="index.html#fn9" id="fnref9">[9]</a></sup> use the trace norm.</p>
<figure>
      <img src="https://ruder.io/content/images/2017/05/mtl_images-002-1.png" style="width: 80%" title="Soft parameter sharing">
<figcaption>Figure 2: Soft parameter sharing for multi-task learning in deep neural networks</figcaption>
</figure>
<p>The constraints used for soft parameter sharing in deep neural networks have been greatly inspired by regularization techniques for MTL that have been developed for other models, which we will soon discuss.</p>
<h1 id="whydoesmtlwork">Why does MTL work?</h1>
<p>Even though an inductive bias obtained through multi-task learning seems intuitively plausible, in order to understand MTL better, we need to look at the mechanisms that underlie it. Most of these have first been proposed by Caruana (1998). For all examples, we will assume that we have two related tasks \(A\) and \(B\), which rely on a common hidden layer representation \(F\).</p>
<h2 id="implicitdataaugmentation">Implicit data augmentation</h2>
<p>MTL effectively increases the sample size that we are using for training our model. As all tasks are at least somewhat noisy, when training a model on some task \(A\), our aim is to learn a good representation for task \(A\) that ideally ignores the data-dependent noise and generalizes well. As different tasks have different noise patterns, a model that learns two tasks simultaneously is able to learn a more general representation. Learning just task \(A\) bears the risk of overfitting to task \(A\), while learning \(A\) and \(B\) jointly enables the model to obtain a better representation \(F\) through averaging the noise patterns.</p>
<h2 id="attentionfocusing">Attention focusing</h2>
<p>If a task is very noisy or data is limited and high-dimensional, it can be difficult for a model to differentiate between relevant and irrelevant features. MTL can help the model focus its attention on those features that actually matter as other tasks will provide additional evidence for the relevance or irrelevance of those features.</p>
<h2 id="eavesdropping">Eavesdropping</h2>
<p>Some features \(G\) are easy to learn for some task \(B\), while being difficult to learn for another task \(A\). This might either be because \(A\) interacts with the features in a more complex way or because other features are impeding the model's ability to learn \(G\). Through MTL, we can allow the model to <em>eavesdrop</em>, i.e. learn \(G\) through task \(B\). The easiest way to do this is through <em>hints</em> <sup class="footnote-ref"><a href="index.html#fn10" id="fnref10">[10]</a></sup>, i.e. directly training the model to predict the most important features.</p>
<h2 id="representationbias">Representation bias</h2>
<p>MTL biases the model to prefer representations that other tasks also prefer. This will also help the model to generalize to new tasks in the future as a hypothesis space that performs well for a sufficiently large number of training tasks will also perform well for learning novel tasks as long as they are from the same environment <sup class="footnote-ref"><a href="index.html#fn11" id="fnref11">[11]</a></sup>.</p>
<h2 id="regularization">Regularization</h2>
<p>Finally, MTL acts as a regularizer by introducing an inductive bias. As such, it reduces the risk of overfitting as well as the Rademacher complexity of the model, i.e. its ability to fit random noise.</p>
<h1 id="mtlinnonneuralmodels">MTL in non-neural models</h1>
<p>In order to better understand MTL in deep neural networks, we will now look to the existing literature on MTL for linear models, kernel methods, and Bayesian algorithms. In particular, we will discuss two main ideas that have been pervasive throughout the history of multi-task learning: enforcing sparsity across tasks through norm regularization; and modelling the relationships between tasks.</p>
<p>Note that many approaches to MTL in the literature deal with a homogenous setting: They assume that all tasks are associated with a single output, e.g. the multi-class MNIST dataset is typically cast as 10 binary classification tasks. More recent approaches deal with a more realistic, heterogeneous setting where each task corresponds to a unique set of outputs.</p>
<h2 id="blocksparseregularization">Block-sparse regularization</h2>
<p>In order to better connect the following approaches, let us first introduce some notation. We have \(T\) tasks. For each task \(t\), we have a model \(m_t\) with parameters \(a_t\) of dimensionality \(d\). We can write the parameters as a column vector \(a_t = \begin{bmatrix}a_{1, t} \ \ldots \ a_{d, t} \end{bmatrix}^\top \). We now stack these column vectors \(a_1, \ldots, a_T\) column by column to form a matrix \(A \in<br>
\mathbb{R}^{d \times T}\). The \(i\)-th row of \(A\) then contains the parameter \(a_{i, \cdot}\) corresponding to the \(i\)-th feature of the model for every task, while the \(j\)-th column of \(A\) contains the parameters \(a_{\cdot,j}\) corresponding to the \(j\)-th model.</p>
<p>Many existing methods make some sparsity assumption with regard to the parameters of our models. <sup class="footnote-ref"><a href="index.html#fn12" id="fnref12">[12]</a></sup> assume that all models share a small set of features. In terms of our task parameter matrix \(A\), this means that all but a few rows are \(0\), which corresponds to only a few features being used across <em>all</em> tasks. In order to enforce this, they generalize the \(\ell_1\) norm to the MTL setting. Recall that the \(\ell_1\) norm is a constraint on the sum of the parameters, which forces all but a few parameters to be exactly \(0\). It is also known as lasso (__l__east __a__bsolute __s__hrinkage and __s__election __o__perator).</p>
<p>While in the single-task setting, the \(\ell_1\) norm is computed based on the parameter vector \(a_t\) of the respective task \(t\), for MTL we compute it over our task parameter matrix \(A\). In order to do this, we first compute an \(\ell_q\) norm across each row \(a_i\) containing the parameter corresponding to the \(i\)-th feature across all tasks, which yields a vector \(b = \begin{bmatrix}|a_1|_q \ldots |a_d|_q \end{bmatrix} \in \mathbb{R}^d\). We then compute the \(\ell_1\) norm of this vector, which forces all but a few entries of \(b\), i.e. rows in \(A\) to be \(0\).</p>
<p>As we can see, depending on what constraint we would like to place on each row, we can use a different \(\ell_q\). In general, we refer to these mixed-norm constraints as \(\ell_1/\ell_q\) norms. They are also known as block-sparse regularization, as they lead to entire rows of \(A\) being set to \(0\). <sup class="footnote-ref"><a href="index.html#fn13" id="fnref13">[13]</a></sup> use \(\ell_1/\ell_\infty\) regularization, while Argyriou et al. (2007) use a mixed \(\ell_1/\ell_2\) norm. The latter is also known as group lasso and was first proposed by <sup class="footnote-ref"><a href="index.html#fn14" id="fnref14">[14]</a></sup>.</p>
<p>Argyriou et al. (2007) also show that the problem of optimizing the non-convex group lasso can be made convex by penalizing the trace norm of \(A\), which forces \(A\) to be low-rank and thereby constrains the column parameter vectors \(a_{\cdot, 1}, \ldots, a_{\cdot, t}\) to live in a low-dimensional subspace. <sup class="footnote-ref"><a href="index.html#fn15" id="fnref15">[15]</a></sup> furthermore establish upper bounds for using the group lasso in multi-task learning.</p>
<p>As much as this block-sparse regularization is intuitively plausible, it is very dependent on the extent to which the features are shared across tasks. <sup class="footnote-ref"><a href="index.html#fn16" id="fnref16">[16]</a></sup> show that if features do not overlap by much, \(\ell_1/\ell_q\) regularization might actually be worse than element-wise \(\ell_1\) regularization.</p>
<p>For this reason, <sup class="footnote-ref"><a href="index.html#fn17" id="fnref17">[17]</a></sup> improve upon block-sparse models by proposing a method that combines block-sparse and element-wise sparse regularization. They decompose the task parameter matrix \(A\) into two matrices \(B\) and \(S\) where \(A = B + S\). \(B\) is then enforced to be block-sparse using \(\ell_1/\ell_\infty\) regularization, while \(S\) is made element-wise sparse using lasso. Recently, <sup class="footnote-ref"><a href="index.html#fn18" id="fnref18">[18]</a></sup> propose a distributed version of group-sparse regularization.</p>
<h2 id="learningtaskrelationships">Learning task relationships</h2>
<p>While the group-sparsity constraint forces our model to only consider a few features, these features are largely used across all tasks. All of the previous approaches thus assume that the tasks used in multi-task learning are closely related. However, each task might not be closely related to all of the available tasks. In those cases, sharing information with an unrelated task might actually hurt performance, a phenomenon known as negative transfer.</p>
<p>Rather than sparsity, we would thus like to leverage prior knowledge indicating that some tasks are related while others are not. In this scenario, a constraint that enforces a clustering of tasks might be more appropriate. <sup class="footnote-ref"><a href="index.html#fn19" id="fnref19">[19]</a></sup> suggest to impose a clustering constraint by penalizing both the norms of our task column vectors \(a_{\cdot, 1}, \ldots, a_{\cdot, t}\) as well as their variance with the following constraint:</p>
<p>\(\Omega = |\bar{a}|^2 + \dfrac{\lambda}{T} \sum^T_{t=1} | a_{\cdot, t} - \bar{a} |^2 \)</p>
<p>where \(\bar{a} = (\sum^T_{t=1} a_{\cdot, t})/T \) is the mean parameter vector. This penalty enforces a clustering of the task parameter vectors \(a_{\cdot, 1}, \ldots, a_{\cdot, t}\) towards their mean that is controlled by \(\lambda\). They apply this constraint to kernel methods, but it is equally applicable to linear models.</p>
<p>A similar constraint for SVMs was also proposed by <sup class="footnote-ref"><a href="index.html#fn20" id="fnref20">[20]</a></sup>. Their constraint is inspired by Bayesian methods and seeks to make all models close to some mean model. In SVMs, the loss thus trades off having a large margin for each SVM with being close to the mean model.</p>
<p><sup class="footnote-ref"><a href="index.html#fn21" id="fnref21">[21]</a></sup> make the assumptions underlying cluster regularization more explicit by formalizing a cluster constraint on \(A\) under the assumption that the number of clusters \(C\) is known in advance. They then decompose the penalty into three separate norms:</p>
<ul>
<li>
<p>A global penalty which measures how large our column parameter vectors are on average: \(\Omega_{mean}(A) = |\bar{a}|^2 \).</p>
</li>
<li>
<p>A measure of between-cluster variance that measures how close to each other the clusters are:  \(\Omega_{between}(A) = \sum^C_{c=1} T_c | \bar{a}_c - \bar{a} |^2 \) where \(T_c\) is the number of tasks in the \(c\)-th cluster and \(\bar{a}_c\) is the mean vector of the task parameter vectors in the \(c\)-th cluster.</p>
</li>
<li>
<p>A measure of within-cluster variance that gauges how compact each cluster is: \(\Omega_{within} = \sum^C_{c=1} \sum_{t \in J(c)} | a_{\cdot, t} - \bar{a}_c |^2 \) where \(J(c)\) is the set of tasks in the \(c\)-th cluster.</p>
</li>
</ul>
<p>The final constraint then is the weighted sum of the three norms:</p>
<p>\(\Omega(A) = \lambda_1 \Omega_{mean}(A) + \lambda_2 \Omega_{between}(A) + \lambda_3 \Omega_{within}(A)\).</p>
<p>As this constraint assumes clusters are known in advance, they introduce a convex relaxation of the above penalty that allows to learn the clusters at the same time.</p>
<p>In another scenario, tasks might not occur in clusters but have an inherent structure. <sup class="footnote-ref"><a href="index.html#fn22" id="fnref22">[22]</a></sup> extend the group lasso to deal with tasks that occur in a tree structure, while <sup class="footnote-ref"><a href="index.html#fn23" id="fnref23">[23]</a></sup> apply it to tasks with graph structures.</p>
<p>While the previous approaches to modelling the relationship between tasks employ norm regularization, other approaches do so without regularization: <sup class="footnote-ref"><a href="index.html#fn24" id="fnref24">[24]</a></sup> were the first ones who presented a task clustering algorithm using k-nearest neighbour, while <sup class="footnote-ref"><a href="index.html#fn25" id="fnref25">[25]</a></sup> learn a common structure from multiple related tasks with an application to semi-supervised learning.</p>
<p>Much other work on learning task relationships for multi-task learning uses Bayesian methods:<br>
<sup class="footnote-ref"><a href="index.html#fn26" id="fnref26">[26]</a></sup> propose a Bayesian neural network for multi-task learning by placing a prior on the model parameters to encourage similar parameters across tasks. <sup class="footnote-ref"><a href="index.html#fn27" id="fnref27">[27]</a></sup> extend Gaussian processes (GP) to MTL by inferring parameters for a shared covariance matrix. As this is computationally very expensive, they adopt a sparse approximation scheme that greedily selects the most informative examples. <sup class="footnote-ref"><a href="index.html#fn28" id="fnref28">[28]</a></sup> also use GP for MTL by assuming that all models are sampled from a common prior.</p>
<p><sup class="footnote-ref"><a href="index.html#fn29" id="fnref29">[29]</a></sup> place a Gaussian as a prior distribution on each task-specific layer. In order to encourage similarity between different tasks, they propose to make the mean task-dependent and introduce a clustering of the tasks using a mixture distribution. Importantly, they require task characteristics that define the clusters and the number of mixtures to be specified in advance.</p>
<p>Building on this, <sup class="footnote-ref"><a href="index.html#fn30" id="fnref30">[30]</a></sup> draw the distribution from a Dirichlet process and enable the model to learn the similarity between tasks as well as the number of clusters. They then share the same model among all tasks in the same cluster. <sup class="footnote-ref"><a href="index.html#fn31" id="fnref31">[31]</a></sup> propose a hierarchical Bayesian model, which learns a latent task hierarchy, while <sup class="footnote-ref"><a href="index.html#fn32" id="fnref32">[32]</a></sup> use a GP-based regularization for MTL and extend a previous GP-based approach to be more computationally feasible in larger settings.</p>
<p>Other approaches focus on the online multi-task learning setting: <sup class="footnote-ref"><a href="index.html#fn33" id="fnref33">[33]</a></sup> adapt some existing methods such as the approach by Evgeniou et al. (2005) to the online setting. They also propose a MTL extension of the regularized Perceptron, which encodes task relatedness in a matrix. They use different forms of regularization to bias this task relatedness matrix, e.g. the closeness of the task characteristic vectors or the dimension of the spanned subspace. Importantly, similar to some earlier approaches, they require the task characteristics that make up this matrix to be provided in advance. <sup class="footnote-ref"><a href="index.html#fn34" id="fnref34">[34]</a></sup> then extend the previous approach by learning the task relationship matrix.</p>
<p><sup class="footnote-ref"><a href="index.html#fn35" id="fnref35">[35]</a></sup> assume that tasks form disjoint groups and that the tasks within each group lie in a low-dimensional subspace. Within each group, tasks share the same feature representation whose parameters are learned jointly together with the group assignment matrix using an alternating minimization scheme. However, a total disjointness between groups might not be the ideal way, as the tasks might still share some features that are helpful for prediction.</p>
<p><sup class="footnote-ref"><a href="index.html#fn36" id="fnref36">[36]</a></sup> in turn allow two tasks from different groups to overlap by assuming that there exist a small number of latent basis tasks. They then model the parameter vector \(a_t\) of every actual task \(t\) as a linear combination of these: \(a_t = Ls_t\) where \(L\ \in \mathbb{R}^{k \times d}\) is a matrix containing the parameter vectors of \(k\) latent tasks, while \(s_t\ \in \mathbb{R}^k\) is a vector containing the coefficients of the linear combination. In addition, they constrain the linear combination to be sparse in the latent tasks; the overlap in the sparsity patterns between two tasks then controls the amount of sharing between these. Finally, <sup class="footnote-ref"><a href="index.html#fn37" id="fnref37">[37]</a></sup> learn a small pool of shared hypotheses and then map each task to a single hypothesis.</p>
<h1 id="recentworkonmtlfordeeplearning">Recent work on MTL for Deep Learning</h1>
<p>While many recent Deep Learning approaches have used multi-task learning -- either explicitly or implicitly -- as part of their model (prominent examples will be featured in the next section), they all employ the two approaches we introduced earlier, hard and soft parameter sharing. In contrast, only a few papers have looked at developing better mechanisms for MTL in deep neural networks.</p>
<h2 id="deeprelationshipnetworks">Deep Relationship Networks</h2>
<p>In MTL for computer vision, approaches often share the convolutional layers, while learning task-specific fully-connected layers. <sup class="footnote-ref"><a href="index.html#fn38" id="fnref38">[38]</a></sup> improve upon these models by proposing Deep Relationship Networks. In addition to the structure of shared and task-specific layers, which can be seen in Figure 3, they place matrix priors on the fully connected layers, which allow the model to learn the relationship between tasks, similar to some of the Bayesian models we have looked at before. This approach, however, still relies on a pre-defined structure for sharing, which may be adequate for well-studied computer vision problems, but prove error-prone for novel tasks.</p>
<figure>
      <img src="https://ruder.io/content/images/2017/05/relationship_networks.png" style="width: 100%" title="Deep Relationship Networks">
<figcaption>Figure 3: A Deep Relationship Network with shared convolutional and task-specific fully connected layers with matrix priors (Long and Wang, 2015).</figcaption>
</figure>
<h2 id="fullyadaptivefeaturesharing">Fully-Adaptive Feature Sharing</h2>
<p>Starting at the other extreme, <sup class="footnote-ref"><a href="index.html#fn39" id="fnref39">[39]</a></sup> propose a bottom-up approach that starts with a thin network and dynamically widens it greedily during training using a criterion that promotes grouping of similar tasks. The widening procedure, which dynamically creates branches can be seen in Figure 4. However, the greedy method might not be able to discover a model that is globally optimal, while assigning each branch to exactly one task does not allow the model to learn more complex interactions between tasks.</p>
<figure>
      <img src="https://ruder.io/content/images/2017/05/fully_adaptive_feature_sharing.png" style="width: 100%" title="Fully-Adaptive Feature Sharing">
<figcaption>Figure 4: The widening procedure for fully-adaptive feature sharing (Lu et al., 2016).</figcaption>
</figure>
<h2 id="crossstitchnetworks">Cross-stitch Networks</h2>
<p><sup class="footnote-ref"><a href="index.html#fn40" id="fnref40">[40]</a></sup> start out with two separate model architectures just as in soft parameter sharing. They then use what they refer to as cross-stitch units to allow the model to determine in what way the task-specific networks leverage the knowledge of the other task by learning a linear combination of the output of the previous layers. Their architecture can be seen in Figure 5, in which they only place cross-stitch units after pooling and fully-connected layers.</p>
<figure>
      <img src="https://ruder.io/content/images/2017/05/cross-stitch_networks.png" style="width: 70%" title="Cross-stitch networks">
<figcaption>Figure 5: Cross-stitch networks for two tasks (Misra et al., 2016).</figcaption>
</figure>
<h2 id="lowsupervision">Low supervision</h2>
<p>In contrast, in natural language processing (NLP), recent work focused on finding better task hierarchies for multi-task learning: <sup class="footnote-ref"><a href="index.html#fn41" id="fnref41">[41]</a></sup> show that low-level tasks, i.e. NLP tasks typically used for preprocessing such as part-of-speech tagging and named entity recognition, should be supervised at lower layers when used as auxiliary task.</p>
<h2 id="ajointmanytaskmodel">A Joint Many-Task Model</h2>
<p>Building on this finding, <sup class="footnote-ref"><a href="index.html#fn42" id="fnref42">[42]</a></sup> pre-define a hierarchical architecture consisting of several NLP tasks, which can be seen in Figure 6, as a joint model for multi-task learning.</p>
<figure>
      <img src="https://ruder.io/content/images/2017/05/joint_many_task_model.png" style="width: 60%" title="Joint Many-Task Model">
<figcaption>Figure 6: A Joint Many-Task Model (Hashimoto et al., 2016).</figcaption>
</figure>
<h2 id="weightinglosseswithuncertainty">Weighting losses with uncertainty</h2>
<p>Instead of learning the structure of sharing, <sup class="footnote-ref"><a href="index.html#fn43" id="fnref43">[43]</a></sup> take a orthogonal approach by considering the uncertainty of each task. They then adjust each task's relative weight in the cost function by deriving a multi-task loss function based on maximizing the Gaussian likelihood with task-dependant uncertainty. Their architecture for per-pixel depth regression, semantic and instance segmentation can be seen in Figure 7.</p>
<figure>
      <img src="https://ruder.io/content/images/2017/05/weighting_using_uncertainty.png" style="width: 70%" title="Uncertainty-based loss function weighting">
<figcaption>Figure 7: Uncertainty-based loss function weighting for multi-task learning (Kendall et al., 2017).</figcaption>
</figure>
<h2 id="tensorfactorisationformtl">Tensor factorisation for MTL</h2>
<p>More recent work seeks to generalize existing approaches to MTL to Deep Learning: <sup class="footnote-ref"><a href="index.html#fn44" id="fnref44">[44]</a></sup> generalize some of the previously discussed matrix factorisation approaches using tensor factorisation to split the model parameters into shared and task-specific parameters for every layer.</p>
<h2 id="sluicenetworks">Sluice Networks</h2>
<p>Finally, we propose Sluice Networks <sup class="footnote-ref"><a href="index.html#fn45" id="fnref45">[45]</a></sup>, a model that generalizes Deep Learning-based MTL approaches such as hard parameter sharing and cross-stitch networks, block-sparse regularization approaches, as well as recent NLP approaches that create a task hierarchy. The model, which can be seen in Figure 8, allows to learn what layers and subspaces should be shared, as well as at what layers the network has learned the best representations of the input sequences.</p>
<figure>
      <img src="https://ruder.io/content/images/2017/05/sluice_network-003.png" style="width: 70%" title="Sluice networks">
<figcaption>Figure 8: A sluice network for two tasks (Ruder et al., 2017).</figcaption>
</figure>
<h2 id="whatshouldishareinmymodel">What should I share in my model?</h2>
<p>Having surveyed these recent approaches, let us now briefly summarize and draw a conclusion on what to share in our deep MTL models. Most approaches in the history of MTL have focused on the scenario where tasks are drawn from the same distribution (Baxter, 1997). While this scenario is beneficial for sharing, it does not always hold. In order to develop robust models for MTL, we thus have to be able to deal with unrelated or only loosely related tasks.</p>
<p>While early work in MTL for Deep Learning has pre-specified which layers to share for each task pairing, this strategy does not scale and heavily biases MTL architectures. Hard parameter sharing, a technique that was originally proposed by Caruana (1996), is still the norm 20 years later. While useful in many scenarios, hard parameter sharing quickly breaks down if tasks are not closely related or require reasoning on different levels. Recent approaches have thus looked towards <em>learning</em> what to share and generally outperform hard parameter sharing. In addition, giving our models the capacity to learn a task hierarchy is helpful, particularly in cases that require different granularities.</p>
<p>As mentioned initially, we are doing MTL as soon as we are optimizing more than one loss function. Rather than constraining our model to compress the knowledge of all tasks into the same parameter space, it is thus helpful to draw on the advances in MTL that we have discussed and enable our model to learn how the tasks should interact with each other.</p>
<h1 id="auxiliarytasks">Auxiliary tasks</h1>
<p>MTL is a natural fit in situations where we are interested in obtaining predictions for multiple tasks at once. Such scenarios are common for instance in finance or economics forecasting, where we might want to predict the value of many possibly related indicators, or in bioinformatics where we might want to predict symptoms for multiple diseases simultaneously. In scenarios such as drug discovery, where tens or hundreds of active compounds should be predicted, MTL accuracy increases continuously with the number of tasks (Ramsundar et al., 2015).</p>
<p>In most situations, however, we only care about performance on one task. In this section, we will thus look at how we can find a suitable auxiliary task in order to still reap the benefits of multi-task learning.</p>
<h2 id="relatedtask">Related task</h2>
<p>Using a related task as an auxiliary task for MTL is the classical choice. To get an idea what a related task can be, we will present some prominent examples. Caruana (1998) uses tasks that predict different characteristics of the road as auxiliary tasks for predicting the steering direction in a self-driving car; <sup class="footnote-ref"><a href="index.html#fn46" id="fnref46">[46]</a></sup> use head pose estimation and facial attribute inference as auxiliary tasks for facial landmark detection; <sup class="footnote-ref"><a href="index.html#fn47" id="fnref47">[47]</a></sup> jointly learn query classification and web search; Girshick (2015) jointly predicts the class and the coordinates of an object in an image; finally, <sup class="footnote-ref"><a href="index.html#fn48" id="fnref48">[48]</a></sup> jointly predict the phoneme duration and frequency profile for text-to-speech.</p>
<h2 id="adversarial">Adversarial</h2>
<p>Often, labeled data for a related task is unavailable. In some circumstances, however, we have access to a task that is <em>opposite</em> of what we want to achieve. This data can be leveraged using an adversarial loss, which does not seek to minimize but maximize the training error using a gradient reversal layer. This setup has found recent success in domain adaptation <sup class="footnote-ref"><a href="index.html#fn49" id="fnref49">[49]</a></sup>. The adversarial task in this case is predicting the domain of the input; by reversing the gradient of the adversarial task, the adversarial task loss is maximized, which is beneficial for the main task as it forces the model to learn representations that cannot distinguish between domains.</p>
<h2 id="hints">Hints</h2>
<p>As mentioned before, MTL can be used to learn features that might not be easy to learn just using the original task. An effective way to achieve this is to use hints, i.e. predicting the features as an auxiliary task. Recent examples of this strategy in the context of natural language processing are <sup class="footnote-ref"><a href="index.html#fn50" id="fnref50">[50]</a></sup> who predict whether an input sentence contains a positive or negative sentiment word as auxiliary tasks for sentiment analysis and <sup class="footnote-ref"><a href="index.html#fn51" id="fnref51">[51]</a></sup> who predict whether a name is present in a sentence as auxiliary task for name error detection.</p>
<h2 id="focusingattention">Focusing attention</h2>
<p>Similarly, the auxiliary task can be used to focus attention on parts of the image that a network might normally ignore. For instance, for learning to steer (Caruana, 1998) a single-task model might typically ignore lane markings as these make up only a small part of the image and are not always present. Predicting lane markings as auxiliary task, however, forces the model to learn to represent them; this knowledge can then also be used for the main task. Analogously, for facial recognition, one might learn to predict the location of facial landmarks as auxiliary tasks, since these are often distinctive.</p>
<h2 id="quantizationsmoothing">Quantization smoothing</h2>
<p>For many tasks, the training objective is quantized, i.e. while a continuous scale might be more plausible, labels are available as a discrete set. This is the case in many scenarios that require human assessment for data gathering, such as predicting the risk of a disease (e.g. low/medium/high) or sentiment analysis (positive/neutral/negative). Using less quantized auxiliary tasks might help in these cases, as they might be learned more easily due to their objective being smoother.</p>
<h2 id="predictinginputs">Predicting inputs</h2>
<p>In some scenarios, it is impractical to use some features as inputs as they are unhelpful for predicting the desired objective. However, they might still be able to guide the learning of the task. In those cases, the features can be used as outputs rather than inputs. <sup class="footnote-ref"><a href="index.html#fn52" id="fnref52">[52]</a></sup> present several problems where this is applicable.</p>
<h2 id="usingthefuturetopredictthepresent">Using the future to predict the present</h2>
<p>In many situations, some features only become available <em>after</em> the predictions are supposed to be made. For instance, for self-driving cars, more accurate measurements of obstacles and lane markings can be made once the car is passing them. Caruana (1998) also gives the example of pneumonia prediction, after which the results of additional medical trials will be available. For these examples, the additional data cannot be used as features as it will not be available as input at runtime. However, it can be used as an auxiliary task to impart additional knowledge to the model during training.</p>
<h2 id="representationlearning">Representation learning</h2>
<p>The goal of an auxiliary task in MTL is to enable the model to learn representations that are shared or helpful for the main task. All auxiliary tasks discussed so far do this implicitly: They are closely related to the main task, so that learning them likely allows the model to learn beneficial representations. A more explicit modelling is possible, for instance by employing a task that is known to enable a model to learn transferable representations. The language modelling objective as employed by Cheng et al. (2015) and <sup class="footnote-ref"><a href="index.html#fn53" id="fnref53">[53]</a></sup> fulfils this role. In a similar vein, an autoencoder objective can also be used as an auxiliary task.</p>
<h2 id="whatauxiliarytasksarehelpful">What auxiliary tasks are helpful?</h2>
<p>In this section, we have discussed different auxiliary tasks that can be used to leverage MTL even if we only care about one task. We still do not know, though, what auxiliary task will be useful in practice. Finding an auxiliary task is largely based on the assumption that the auxiliary task should be related to the main task in some way and that it should be helpful for predicting the main task.</p>
<p>However, we still do not have a good notion of when two tasks should be considered similar or related. Caruana (1998) defines two tasks to be similar if they use the same features to make a decision. Baxter (2000) argues only theoretically that related tasks share a common optimal hypothesis class, i.e. have the same inductive bias. <sup class="footnote-ref"><a href="index.html#fn54" id="fnref54">[54]</a></sup> propose that two tasks are \(\mathcal{F}\)-related if the data for both tasks can be generated from a fixed probability distribution using a set of transformations \(\mathcal{F}\). While this allows to reason over tasks where different sensors collect data for the same classification problem, e.g. object recognition with data from cameras with different angles and lighting conditions, it is not applicable to tasks that do not deal with the same problem. Xue et al. (2007) finally argue that two tasks are similar if their classification boundaries, i.e. parameter vectors are close.</p>
<p>In spite of these early theoretical advances in understanding task relatedness, we have not made much recent progress towards this goal. Task similarity is not binary, but resides on a spectrum. More similar tasks should help more in MTL, while less similar tasks should help less. Allowing our models to learn what to share with each task might allow us to temporarily circumvent the lack of theory and make better use even of only loosely related tasks. However, we also need to develop a more principled notion of task similarity with regard to multi-task learning in order to know which tasks we should prefer.</p>
<p>Recent work <sup class="footnote-ref"><a href="index.html#fn55" id="fnref55">[55]</a></sup> have found auxiliary tasks with compact and uniform label distributions to be preferable for sequence tagging problems in NLP, which we have confirmed in experiments (Ruder et al., 2017). In addition, gains have been found to be more likely for main tasks that quickly plateau with non-plateauing auxiliary tasks <sup class="footnote-ref"><a href="index.html#fn56" id="fnref56">[56]</a></sup>.</p>
<p>These experiments, however, have so far been limited in scope and recent findings only provide the first clues towards a deeper understanding of multi-task learning in neural networks.</p>
<h1 id="conclusion">Conclusion</h1>
<p>In this overview, I have reviewed both the history of literature in multi-task learning as well as more recent work on MTL for Deep Learning. While MTL is being more frequently used, the 20-year old hard parameter sharing paradigm is still pervasive for neural-network based MTL. Recent advances on learning what to share, however, are promising. At the same time, our understanding of tasks -- their similarity, relationship, hierarchy, and benefit for MTL -- is still limited and we need to learn more about them to gain a better understanding of the generalization capabilities of MTL with regard to deep neural networks.</p>
<p>I hope you found this overview helpful. If I made any error, missed a reference, or misrepresented some aspect, or if you would just like to share your thoughts, please leave a comment below.</p>
<h1 id="printableversionandcitation">Printable version and citation</h1>
<p>This blog post is also available as an <a href="https://arxiv.org/abs/1706.05098">article on arXiv</a>, in case you want to refer to it later.</p>
<p>In case you found it helpful, consider citing the corresponding arXiv article as:<br>
<em>Sebastian Ruder (2017). An Overview of Multi-Task Learning in Deep Neural Networks. arXiv preprint arXiv:1706.05098.</em></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Collobert, R., &amp; Weston, J. (2008). A unified architecture for natural language processing. Proceedings of the 25th International Conference on Machine Learning - ICML ’08, 20(1), 160–167. <a href="https://doi.org/10.1145/1390156.1390177">https://doi.org/10.1145/1390156.1390177</a> <a href="index.html#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Deng, L., Hinton, G. E., &amp; Kingsbury, B. (2013). New types of deep neural network learning for speech recognition and related applications: An overview. 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, 8599–8603. <a href="https://doi.org/10.1109/ICASSP.2013.6639344">https://doi.org/10.1109/ICASSP.2013.6639344</a> <a href="index.html#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Girshick, R. (2015). Fast R-CNN. In Proceedings of the IEEE International Conference on Computer Vision (pp. 1440–1448). <a href="https://doi.org/10.1109/iccv.2015.169">https://doi.org/10.1109/iccv.2015.169</a> <a href="index.html#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Ramsundar, B., Kearnes, S., Riley, P., Webster, D., Konerding, D., &amp; Pande, V. (2015). Massively Multitask Networks for Drug Discovery. <a href="https://doi.org/https://arxiv.org/abs/1502.02072">https://doi.org/https://arxiv.org/abs/1502.02072</a> <a href="index.html#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>Caruana, R. (1998). Multitask Learning. Autonomous Agents and Multi-Agent Systems, 27(1), 95–133. <a href="https://doi.org/10.1016/j.csl.2009.08.003">https://doi.org/10.1016/j.csl.2009.08.003</a> <a href="index.html#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>Caruana, R. &quot;Multitask learning: A knowledge-based source of inductive bias.&quot; Proceedings of the Tenth International Conference on Machine Learning. 1993. <a href="index.html#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p>Baxter, J. (1997). A Bayesian/information theoretic model of learning to learn via multiple task sampling. Machine Learning, 28, 7–39. Retrieved from <a href="http://link.springer.com/article/10.1023/A:1007327622663">http://link.springer.com/article/10.1023/A:1007327622663</a> <a href="index.html#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p>Duong, L., Cohn, T., Bird, S., &amp; Cook, P. (2015). Low Resource Dependency Parsing: Cross-lingual Parameter Sharing in a Neural Network Parser. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), 845–850. <a href="index.html#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p>Yang, Y., &amp; Hospedales, T. M. (2017). Trace Norm Regularised Deep Multi-Task Learning. In Workshop track - ICLR 2017. Retrieved from <a href="http://arxiv.org/abs/1606.04038">http://arxiv.org/abs/1606.04038</a> <a href="index.html#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p>Abu-Mostafa, Y. S. (1990). Learning from hints in neural networks. Journal of Complexity, 6(2), 192–198. <a href="https://doi.org/10.1016/0885-064X(90)90006-Y">https://doi.org/10.1016/0885-064X(90)90006-Y</a> <a href="index.html#fnref10" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p>Baxter, J. (2000). A Model of Inductive Bias Learning. Journal of Artificial Intelligence Research, 12, 149–198. <a href="index.html#fnref11" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p>Argyriou, A., &amp; Pontil, M. (2007). Multi-Task Feature Learning. In Advances in Neural Information Processing Systems. <a href="http://doi.org/10.1007/s10994-007-5040-8">http://doi.org/10.1007/s10994-007-5040-8</a> <a href="index.html#fnref12" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p>C.Zhang and J.Huang. Model selection consistency of the lasso selection in high-dimensional linear regression. Annals of Statistics, 36:1567–1594, 2008 <a href="index.html#fnref13" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p>Yuan, Ming, and Yi Lin. &quot;Model selection and estimation in regression with grouped variables.&quot; Journal of the Royal Statistical Society: Series B (Statistical Methodology) 68.1 (2006): 49-67. <a href="index.html#fnref14" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn15" class="footnote-item"><p>Lounici, K., Pontil, M., Tsybakov, A. B., &amp; van de Geer, S. (2009). Taking Advantage of Sparsity in Multi-Task Learning. Stat, (1). Retrieved from <a href="http://arxiv.org/pdf/0903.1468">http://arxiv.org/pdf/0903.1468</a> <a href="index.html#fnref15" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn16" class="footnote-item"><p>Negahban, S., &amp; Wainwright, M. J. (2008). Joint support recovery under high-dimensional scaling : Benefits and perils of \(\ell_{1,\infty}\)-regularization. Advances in Neural Information Processing Systems, 1161–1168. <a href="index.html#fnref16" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn17" class="footnote-item"><p>Jalali, A., Ravikumar, P., Sanghavi, S., &amp; Ruan, C. (2010). A Dirty Model for Multi-task Learning. Advances in Neural Information Processing Systems. Retrieved from <a href="https://papers.nips.cc/paper/4125-a-dirty-model-for-multi-task-learning.pdf">https://papers.nips.cc/paper/4125-a-dirty-model-for-multi-task-learning.pdf</a> <a href="index.html#fnref17" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn18" class="footnote-item"><p>Liu, S., Pan, S. J., &amp; Ho, Q. (2016). Distributed Multi-task Relationship Learning. In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics (AISTATS) (pp. 751–760). Retrieved from <a href="http://arxiv.org/abs/1612.04022">http://arxiv.org/abs/1612.04022</a> <a href="index.html#fnref18" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn19" class="footnote-item"><p>Evgeniou, T., Micchelli, C., &amp; Pontil, M. (2005). Learning multiple tasks with kernel methods. Journal of Machine Learning Research, 6, 615–637. Retrieved from <a href="http://discovery.ucl.ac.uk/13423/">http://discovery.ucl.ac.uk/13423/</a> <a href="index.html#fnref19" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn20" class="footnote-item"><p>Evgeniou, T., &amp; Pontil, M. (2004). Regularized multi-task learning. International Conference on Knowledge Discovery and Data Mining, 109. <a href="https://doi.org/10.1145/1014052.1014067">https://doi.org/10.1145/1014052.1014067</a> <a href="index.html#fnref20" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn21" class="footnote-item"><p>Jacob, L., Vert, J., Bach, F. R., &amp; Vert, J. (2009). Clustered Multi-Task Learning: A Convex Formulation. Advances in Neural Information Processing Systems 21, 745–752. Retrieved from <a href="http://eprints.pascal-network.org/archive/00004705/%5Cnhttp://papers.nips.cc/paper/3499-clustered-multi-task-learning-a-convex-formulation.pdf">http://eprints.pascal-network.org/archive/00004705/\nhttp://papers.nips.cc/paper/3499-clustered-multi-task-learning-a-convex-formulation.pdf</a> <a href="index.html#fnref21" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn22" class="footnote-item"><p>Kim, S., &amp; Xing, E. P. (2010). Tree-Guided Group Lasso for Multi-Task Regression with Structured Sparsity. 27th International Conference on Machine Learning, 1–14. <a href="https://doi.org/10.1214/12-AOAS549">https://doi.org/10.1214/12-AOAS549</a> <a href="index.html#fnref22" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn23" class="footnote-item"><p>Chen, X., Kim, S., Lin, Q., Carbonell, J. G., &amp; Xing, E. P. (2010). Graph-Structured Multi-task Regression and an Efficient Optimization Method for General Fused Lasso, 1–21. <a href="https://doi.org/10.1146/annurev.arplant.56.032604.144204">https://doi.org/10.1146/annurev.arplant.56.032604.144204</a> <a href="index.html#fnref23" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn24" class="footnote-item"><p>Thrun, S., &amp; O’Sullivan, J. (1996). Discovering Structure in Multiple Learning Tasks: The TC Algorithm. Proceedings of the Thirteenth International Conference on Machine Learning, 28(1), 5–5. Retrieved from <a href="http://scholar.google.com/scholar?cluster=956054018507723832&amp;hl=en">http://scholar.google.com/scholar?cluster=956054018507723832&amp;hl=en</a> <a href="index.html#fnref24" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn25" class="footnote-item"><p>Ando, R. K., &amp; Tong, Z. (2005). A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data. Journal of Machine Learning Research, 6, 1817–1853. <a href="index.html#fnref25" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn26" class="footnote-item"><p>Heskes, T. (2000). Empirical Bayes for Learning to Learn. Proceedings of the Seventeenth International Conference on Machine Learning, 367–364. <a href="index.html#fnref26" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn27" class="footnote-item"><p>Lawrence, N. D., &amp; Platt, J. C. (2004). Learning to learn with the informative vector machine. Twenty-First International Conference on Machine Learning  - ICML ’04, 65. <a href="https://doi.org/10.1145/1015330.1015382">https://doi.org/10.1145/1015330.1015382</a> <a href="index.html#fnref27" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn28" class="footnote-item"><p>Yu, K., Tresp, V., &amp; Schwaighofer, A. (2005). Learning Gaussian processes from multiple tasks. Proceedings of the International Conference on Machine Learning (ICML), 22, 1012–1019. <a href="https://doi.org/10.1145/1102351.1102479">https://doi.org/10.1145/1102351.1102479</a> <a href="index.html#fnref28" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn29" class="footnote-item"><p>Bakker, B., &amp; Heskes, T. (2003). Task Clustering and Gating for Bayesian Multitask Learning. Journal of Machine Learning Research, 1(1), 83–99. <a href="https://doi.org/10.1162/153244304322765658">https://doi.org/10.1162/153244304322765658</a> <a href="index.html#fnref29" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn30" class="footnote-item"><p>Xue, Y., Liao, X., Carin, L., &amp; Krishnapuram, B. (2007). Multi-Task Learning for Classification with Dirichlet Process Priors. Journal of Machine Learning Research, 8, 35–63. <a href="index.html#fnref30" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn31" class="footnote-item"><p>Daumé III, H. (2009). Bayesian multitask learning with latent hierarchies, 135–142. Retrieved from <a href="http://dl.acm.org.sci-hub.io/citation.cfm?id=1795131">http://dl.acm.org.sci-hub.io/citation.cfm?id=1795131</a> <a href="index.html#fnref31" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn32" class="footnote-item"><p>Zhang, Y., &amp; Yeung, D. (2010). A Convex Formulation for Learning Task Relationships in Multi-Task Learning. Uai, 733–442. <a href="index.html#fnref32" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn33" class="footnote-item"><p>Cavallanti, G., Cesa-Bianchi, N., &amp; Gentile, C. (2010). Linear Algorithms for Online Multitask Classification. Journal of Machine Learning Research, 11, 2901–2934. <a href="index.html#fnref33" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn34" class="footnote-item"><p>Saha, A., Rai, P., Daumé, H., &amp; Venkatasubramanian, S. (2011). Online learning of multiple tasks and their relationships. Journal of Machine Learning Research, 15, 643–651. Retrieved from <a href="http://www.scopus.com/inward/record.url?eid=2-s2.0-84862275213&amp;partnerID=tZOtx3y1">http://www.scopus.com/inward/record.url?eid=2-s2.0-84862275213&amp;partnerID=tZOtx3y1</a> <a href="index.html#fnref34" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn35" class="footnote-item"><p>Kang, Z., Grauman, K., &amp; Sha, F. (2011). Learning with whom to share in multi-task feature learning. Proceedings of the 28th International Conference on Machine Learning, (4), 4–5. Retrieved from <a href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Kang_344.pdf">http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Kang_344.pdf</a> <a href="index.html#fnref35" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn36" class="footnote-item"><p>Kumar, A., &amp; Daumé III, H. (2012). Learning Task Grouping and Overlap in Multi-task Learning. Proceedings of the 29th International Conference on Machine Learning, 1383–1390. <a href="index.html#fnref36" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn37" class="footnote-item"><p>Crammer, K., &amp; Mansour, Y. (2012). Learning Multiple Tasks Using Shared Hypotheses. Neural Information Processing Systems (NIPS), 1484–1492 <a href="index.html#fnref37" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn38" class="footnote-item"><p>Long, M., &amp; Wang, J. (2015). Learning Multiple Tasks with Deep Relationship Networks. arXiv Preprint arXiv:1506.02117. Retrieved from <a href="http://arxiv.org/abs/1506.02117">http://arxiv.org/abs/1506.02117</a> <a href="index.html#fnref38" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn39" class="footnote-item"><p>Lu, Y., Kumar, A., Zhai, S., Cheng, Y., Javidi, T., &amp; Feris, R. (2016). Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification. Retrieved from <a href="http://arxiv.org/abs/1611.05377">http://arxiv.org/abs/1611.05377</a> <a href="index.html#fnref39" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn40" class="footnote-item"><p>Misra, I., Shrivastava, A., Gupta, A., &amp; Hebert, M. (2016). Cross-stitch Networks for Multi-task Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. <a href="https://doi.org/10.1109/CVPR.2016.433">https://doi.org/10.1109/CVPR.2016.433</a> <a href="index.html#fnref40" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn41" class="footnote-item"><p>Søgaard, A., &amp; Goldberg, Y. (2016). Deep multi-task learning with low level tasks supervised at lower layers. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 231–235. <a href="index.html#fnref41" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn42" class="footnote-item"><p>Hashimoto, K., Xiong, C., Tsuruoka, Y., &amp; Socher, R. (2016). A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks. arXiv Preprint arXiv:1611.01587. Retrieved from <a href="http://arxiv.org/abs/1611.01587">http://arxiv.org/abs/1611.01587</a> <a href="index.html#fnref42" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn43" class="footnote-item"><p>Kendall, A., Gal, Y., &amp; Cipolla, R. (2017). Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics. Retrieved from <a href="http://arxiv.org/abs/1705.07115">http://arxiv.org/abs/1705.07115</a> <a href="index.html#fnref43" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn44" class="footnote-item"><p>Yang, Y., &amp; Hospedales, T. (2017). Deep Multi-task Representation Learning: A Tensor Factorisation Approach. In ICLR 2017. <a href="https://doi.org/10.1002/joe.20070">https://doi.org/10.1002/joe.20070</a> <a href="index.html#fnref44" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn45" class="footnote-item"><p>Ruder, S., Bingel, J., Augenstein, I., &amp; Søgaard, A. (2017). Sluice networks: Learning what to share between loosely related tasks. Retrieved from <a href="http://arxiv.org/abs/1705.08142">http://arxiv.org/abs/1705.08142</a> <a href="index.html#fnref45" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn46" class="footnote-item"><p>Zhang, Z., Luo, P., Loy, C. C., &amp; Tang, X. (2014). Facial Landmark Detection by Deep Multi-task Learning. In European Conference on Computer Vision (pp. 94–108). <a href="https://doi.org/10.1007/978-3-319-10599-4_7">https://doi.org/10.1007/978-3-319-10599-4_7</a> <a href="index.html#fnref46" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn47" class="footnote-item"><p>Liu, X., Gao, J., He, X., Deng, L., Duh, K., &amp; Wang, Y.-Y. (2015). Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval. Naacl-2015, 912–921. <a href="index.html#fnref47" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn48" class="footnote-item"><p>Arık, S. Ö., Chrzanowski, M., Coates, A., Diamos, G., Gibiansky, A., Kang, Y., … Shoeybi, M. (2017). Deep Voice: Real-time Neural Text-to-Speech. In ICML 2017. <a href="index.html#fnref48" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn49" class="footnote-item"><p>Ganin, Y., &amp; Lempitsky, V. (2015). Unsupervised Domain Adaptation by Backpropagation. In Proceedings of the 32nd International Conference on Machine Learning. (Vol. 37). <a href="index.html#fnref49" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn50" class="footnote-item"><p>Yu, J., &amp; Jiang, J. (2016). Learning Sentence Embeddings with Auxiliary Tasks for Cross-Domain Sentiment Classification. Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP2016), 236–246. Retrieved from <a href="http://www.aclweb.org/anthology/D/D16/D16-1023.pdf">http://www.aclweb.org/anthology/D/D16/D16-1023.pdf</a> <a href="index.html#fnref50" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn51" class="footnote-item"><p>Cheng, H., Fang, H., &amp; Ostendorf, M. (2015). Open-Domain Name Error Detection using a Multi-Task RNN. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (pp. 737–746). <a href="index.html#fnref51" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn52" class="footnote-item"><p>Caruana, R., &amp; Sa, V. R. de. (1997). Promoting poor features to supervisors: Some inputs work better as outputs. Advances in Neural Information Processing Systems 9: Proceedings of The 1996 Conference, 9, 389. Retrieved from <a href="http://scholar.google.com/scholar?start=20&amp;q=author:%22Rich+Caruana%22&amp;hl=en#6">http://scholar.google.com/scholar?start=20&amp;q=author:&quot;Rich+Caruana&quot;&amp;hl=en#6</a> <a href="index.html#fnref52" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn53" class="footnote-item"><p>Rei, M. (2017). Semi-supervised Multitask Learning for Sequence Labeling. In ACL 2017. <a href="index.html#fnref53" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn54" class="footnote-item"><p>Ben-David, S., &amp; Schuller, R. (2003). Exploiting task relatedness for multiple task learning. Learning Theory and Kernel Machines, 567–580. <a href="https://doi.org/10.1007/978-3-540-45167-9_41">https://doi.org/10.1007/978-3-540-45167-9_41</a> <a href="index.html#fnref54" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn55" class="footnote-item"><p>Alonso, H. M., &amp; Plank, B. (2017). When is multitask learning effective? Multitask learning for semantic sequence prediction under varying data conditions. In EACL. Retrieved from <a href="http://arxiv.org/abs/1612.02251">http://arxiv.org/abs/1612.02251</a> <a href="index.html#fnref55" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn56" class="footnote-item"><p>Bingel, J., &amp; Søgaard, A. (2017). Identifying beneficial task relations for multi-task learning in deep neural networks. In EACL. Retrieved from <a href="http://arxiv.org/abs/1702.08303">http://arxiv.org/abs/1702.08303</a> <a href="index.html#fnref56" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
                </div>
            </section>



        </article>

    </div>
</main>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = '/multi-task/';  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = "ghost-11"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://EXAMPLE.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                            

<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
                <article class="read-next-card">
                    <header class="read-next-card-header">
                        <h3><span>More in</span> <a href="../tag/multi-task-learning/index.html">multi-task learning</a></h3>
                    </header>
                    <div class="read-next-card-content">
                        <ul>
                            <li>
                                <h4><a href="../thesis/index.html">Neural Transfer Learning for Natural Language Processing (PhD thesis)</a></h4>
                                <div class="read-next-card-meta">
                                    <p><time datetime="2019-03-23">23 Mar 2019</time> –
                                        1 min read</p>
                                </div>
                            </li>
                            <li>
                                <h4><a href="../10-exciting-ideas-of-2018-in-nlp/index.html">10 Exciting Ideas of 2018 in NLP</a></h4>
                                <div class="read-next-card-meta">
                                    <p><time datetime="2018-12-19">19 Dec 2018</time> –
                                        8 min read</p>
                                </div>
                            </li>
                            <li>
                                <h4><a href="../a-review-of-the-recent-history-of-nlp/index.html">A Review of the Neural History of Natural Language Processing</a></h4>
                                <div class="read-next-card-meta">
                                    <p><time datetime="2018-10-01">1 Oct 2018</time> –
                                        29 min read</p>
                                </div>
                            </li>
                        </ul>
                    </div>
                    <footer class="read-next-card-footer">
                        <a href="../tag/multi-task-learning/index.html">See all 5 posts
                            →</a>
                    </footer>
                </article>

                <article class="post-card post tag-natural-language-processing ">

    <a class="post-card-image-link" href="../deep-learning-nlp-best-practices/index.html">
        <img class="post-card-image"
            srcset="../content/images/size/w300/2017/07/attention_bahdanau-1.png 300w,
                   ../content/images/size/w600/2017/07/attention_bahdanau-1.png 600w,
                  ../content/images/size/w1000/2017/07/attention_bahdanau-1.png 1000w,
                 ../content/images/size/w2000/2017/07/attention_bahdanau-1.png 2000w"
            sizes="(max-width: 1000px) 400px, 700px"
            src="../content/images/size/w600/2017/07/attention_bahdanau-1.png"
            alt="Deep Learning for NLP Best Practices"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../deep-learning-nlp-best-practices/index.html">

            <header class="post-card-header">
                    <div class="post-card-primary-tag">natural language processing</div>
                <h2 class="post-card-title">Deep Learning for NLP Best Practices</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>Neural networks are widely used in NLP, but many details such as task or domain-specific considerations are left to the practitioner. This post collects best practices that are relevant for most tasks in NLP.</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>
            
                    <a href="../author/sebastian/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../content/images/size/w100/2019/02/new_profile_photo_square-1.jpg" alt="Sebastian Ruder" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/sebastian/index.html">Sebastian Ruder</a></span>
                <span class="post-card-byline-date"><time datetime="2017-07-25">25 Jul 2017</time> <span class="bull">&bull;</span> 23 min read</span>
            </div>
        </footer>

    </div>

</article>

                <article class="post-card post tag-transfer-learning tag-domain-adaptation ">

    <a class="post-card-image-link" href="../transfer-learning/index.html">
        <img class="post-card-image"
            srcset="../content/images/size/w300/2017/03/transfer_learning_digits.png 300w,
                   ../content/images/size/w600/2017/03/transfer_learning_digits.png 600w,
                  ../content/images/size/w1000/2017/03/transfer_learning_digits.png 1000w,
                 ../content/images/size/w2000/2017/03/transfer_learning_digits.png 2000w"
            sizes="(max-width: 1000px) 400px, 700px"
            src="../content/images/size/w600/2017/03/transfer_learning_digits.png"
            alt="Transfer Learning - Machine Learning&#x27;s Next Frontier"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../transfer-learning/index.html">

            <header class="post-card-header">
                    <div class="post-card-primary-tag">transfer learning</div>
                <h2 class="post-card-title">Transfer Learning - Machine Learning&#x27;s Next Frontier</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>Deep learning models excel at learning from a large number of labeled examples, but typically do not generalize to conditions not seen during training. This post gives an overview of transfer learning, motivates why it warrants our application, and discusses practical applications and methods.</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>
            
                    <a href="../author/sebastian/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../content/images/size/w100/2019/02/new_profile_photo_square-1.jpg" alt="Sebastian Ruder" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/sebastian/index.html">Sebastian Ruder</a></span>
                <span class="post-card-byline-date"><time datetime="2017-03-21">21 Mar 2017</time> <span class="bull">&bull;</span> 28 min read</span>
            </div>
        </footer>

    </div>

</article>
        </div>
    </div>
</aside>




        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://ruder.io">Sebastian Ruder</a> &copy; 2021</section>
                <nav class="site-footer-nav">
                    <a href="https://ruder.io">Latest Posts</a>
                    
                    <a href="https://twitter.com/seb_ruder" target="_blank" rel="noopener">Twitter</a>
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>


    <script
        src="https://code.jquery.com/jquery-3.4.1.min.js"
        integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
        crossorigin="anonymous">
    </script>
    <script src="../assets/built/casper.js?v=858352cb6c"></script>

    <script>
        // Parse the URL parameter
        function getParameterByName(name, url) {
            if (!url) url = window.location.href;
            name = name.replace(/[\[\]]/g, "\\$&");
            var regex = new RegExp("[?&]" + name + "(=([^&#]*)|&|#|$)"),
                results = regex.exec(url);
            if (!results) return null;
            if (!results[2]) return '';
            return decodeURIComponent(results[2].replace(/\+/g, " "));
        }

        // Give the parameter a variable name
        var action = getParameterByName('action');

        $(document).ready(function () {
            if (action == 'subscribe') {
                $('body').addClass("subscribe-success");
            }

            $('.subscribe-success-message .subscribe-close').click(function () {
                $('.subscribe-success-message').addClass('close');
            });

            // Reset form on opening subscrion overlay
            $('.subscribe-button').click(function() {
                $('.subscribe-overlay form').removeClass();
                $('.subscribe-email').val('');
            });
        });
    </script>

    <script>
    $(document).ready(function () {
        // FitVids - start
        var $postContent = $(".post-full-content");
        $postContent.fitVids();
        // FitVids - end

        // Replace nav with title on scroll - start
        Casper.stickyNavTitle({
            navSelector: '.site-nav-main',
            titleSelector: '.post-full-title',
            activeClass: 'nav-post-title-active'
        });
        // Replace nav with title on scroll - end

        // Hover on avatar
        var hoverTimeout;
        $('.author-list-item').hover(function () {
            var $this = $(this);

            clearTimeout(hoverTimeout);

            $('.author-card').removeClass('hovered');
            $(this).children('.author-card').addClass('hovered');

        }, function () {
            var $this = $(this);

            hoverTimeout = setTimeout(function () {
                $this.children('.author-card').removeClass('hovered');
            }, 800);
        });
    });
</script>


    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.1.6/zepto.min.js"></script>
<script>jQuery = Zepto</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/plugins/line-numbers/prism-line-numbers.min.js"></script>
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism.min.css" />
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/plugins/line-numbers/prism-line-numbers.min.css" />
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism-coy.min.css" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-python.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-60512592-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-60512592-1');
</script>

</body>
</html>

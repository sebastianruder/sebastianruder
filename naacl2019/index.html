<!DOCTYPE html>
<html lang="en">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>NAACL 2019 Highlights</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="../assets/built/screen.css?v=8587ecf4f6" />

    <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon" />
    <link rel="canonical" href="https://ruder.io/naacl2019/" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <link rel="amphtml" href="https://ruder.io/naacl2019/amp/" />
    
    <meta property="og:site_name" content="Sebastian Ruder" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="NAACL 2019 Highlights" />
    <meta property="og:description" content="This post discusses highlights of NAACL 2019. It covers transfer learning, common sense reasoning, natural language generation, bias, non-English languages, and diversity and inclusion." />
    <meta property="og:url" content="https://ruder.io/naacl2019/" />
    <meta property="og:image" content="https://ruder.io/content/images/2019/06/transfer_learning_tutorial_room-4.jpg" />
    <meta property="article:published_time" content="2019-06-09T20:56:15.000Z" />
    <meta property="article:modified_time" content="2019-06-22T11:05:37.000Z" />
    <meta property="article:tag" content="events" />
    <meta property="article:tag" content="transfer learning" />
    <meta property="article:tag" content="cross-lingual" />
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="NAACL 2019 Highlights" />
    <meta name="twitter:description" content="This post discusses highlights of NAACL 2019. It covers transfer learning, common sense reasoning, natural language generation, bias, non-English languages, and diversity and inclusion." />
    <meta name="twitter:url" content="https://ruder.io/naacl2019/" />
    <meta name="twitter:image" content="https://ruder.io/content/images/2019/06/transfer_learning_tutorial_room-4.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Sebastian Ruder" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="events, transfer learning, cross-lingual" />
    <meta name="twitter:site" content="@seb_ruder" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="1125" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Sebastian Ruder",
        "url": "https://ruder.io/",
        "logo": {
            "@type": "ImageObject",
            "url": {
                "@type": "ImageObject",
                "url": "https://ruder.io/favicon.ico",
                "width": 48,
                "height": 48
            }
        }
    },
    "author": {
        "@type": "Person",
        "name": "Sebastian Ruder",
        "image": {
            "@type": "ImageObject",
            "url": "https://ruder.io/content/images/2019/02/new_profile_photo_square-1.jpg",
            "width": 2000,
            "height": 2000
        },
        "url": "https://ruder.io/author/sebastian/",
        "sameAs": []
    },
    "headline": "NAACL 2019 Highlights",
    "url": "https://ruder.io/naacl2019/",
    "datePublished": "2019-06-09T20:56:15.000Z",
    "dateModified": "2019-06-22T11:05:37.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://ruder.io/content/images/2019/06/transfer_learning_tutorial_room-4.jpg",
        "width": 2000,
        "height": 1125
    },
    "keywords": "events, transfer learning, cross-lingual",
    "description": "This post discusses highlights of NAACL 2019. It covers transfer learning, common sense reasoning, natural language generation, bias, non-English languages, and diversity and inclusion.",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://ruder.io/"
    }
}
    </script>

    <meta name="generator" content="Ghost 3.11" />
    <link rel="alternate" type="application/rss+xml" title="Sebastian Ruder" href="https://ruder.io/rss/" />
    <script>
var profile_title = 'Sebastian Ruder';
</script>
<script>
var disqus_shortname = 'sebastianruder';
</script>
<script>
var profile_resume ='NLP PhD student';
</script>
<script>
var ga_id = 'UA-60512592-1';
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]],
        processEscapes: true
    }
});
</script>

</head>
<body class="post-template tag-events tag-transfer-learning tag-cross-lingual">

    <div class="site-wrapper">

        

<header class="site-header">
    <div class="outer site-nav-main">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left-wrapper">
        <div class="site-nav-left">
                <a class="site-nav-logo" href="https://ruder.io">Sebastian Ruder</a>
            <div class="site-nav-content">
                    <ul class="nav" role="menu">
    <li class="nav-about" role="menuitem"><a href="https://ruder.io/about/">About</a></li>
    <li class="nav-tags" role="menuitem"><a href="https://ruder.io/tags/">Tags</a></li>
    <li class="nav-papers" role="menuitem"><a href="https://ruder.io/publications/">Papers</a></li>
    <li class="nav-talks" role="menuitem"><a href="https://ruder.io/talks/">Talks</a></li>
    <li class="nav-news" role="menuitem"><a href="https://ruder.io/news/">News</a></li>
    <li class="nav-faq" role="menuitem"><a href="https://ruder.io/faq/">FAQ</a></li>
    <li class="nav-sign-up-for-nlp-news" role="menuitem"><a href="https://ruder.io/nlp-news/">Sign up for NLP News</a></li>
    <li class="nav-nlp-progress" role="menuitem"><a href="https://nlpprogress.com/">NLP Progress</a></li>
    <li class="nav-contact" role="menuitem"><a href="https://ruder.io/contact/">Contact</a></li>
</ul>

                    <span class="nav-post-title dash">NAACL 2019 Highlights</span>
            </div>
        </div>
    </div>
    <div class="site-nav-right">
            <div class="social-links">
                    <a class="social-link social-link-tw" href="https://twitter.com/seb_ruder" title="Twitter" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            </div>
                <a class="rss-button" href="https://ruder.io/rss/index.rss" title="RSS" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
</a>

    </div>
</nav>
    </div>
</div></header>


<main id="site-main" class="site-main outer">
    <div class="inner">

        <article class="post-full post tag-events tag-transfer-learning tag-cross-lingual ">

            <header class="post-full-header">

                <section class="post-full-tags">
                    <a href="../tag/events/index.html">events</a>
                </section>

                <h1 class="post-full-title">NAACL 2019 Highlights</h1>

                <p class="post-full-custom-excerpt">This post discusses highlights of NAACL 2019. It covers transfer learning, common sense reasoning, natural language generation, bias, non-English languages, and diversity and inclusion.</p>

                <div class="post-full-byline">

                    <section class="post-full-byline-content">

                        <ul class="author-list">
                            <li class="author-list-item">

                                <div class="author-card">
                                    <img class="author-profile-image" src="../content/images/size/w100/2019/02/new_profile_photo_square-1.jpg" alt="Sebastian Ruder" />
                                    <div class="author-info">
                                        <h2>Sebastian Ruder</h2>
                                        <p>Read <a href="../author/sebastian/index.html">more posts</a> by this author.</p>
                                    </div>
                                </div>

                                <a href="../author/sebastian/index.html" class="author-avatar">
                                    <img class="author-profile-image" src="../content/images/size/w100/2019/02/new_profile_photo_square-1.jpg" alt="Sebastian Ruder" />
                                </a>

                            </li>
                        </ul>

                        <section class="post-full-byline-meta">
                            <h4 class="author-name"><a href="../author/sebastian/index.html">Sebastian Ruder</a></h4>
                            <div class="byline-meta-content">
                                <time class="byline-meta-date" datetime="2019-06-09">9 Jun 2019</time>
                                <span class="byline-reading-time"><span class="bull">&bull;</span> 8 min read</span>
                            </div>
                        </section>

                    </section>


                </div>
            </header>

            <figure class="post-full-image">
                <img
                    srcset="../content/images/size/w300/2019/06/transfer_learning_tutorial_room-4.jpg 300w,
                           ../content/images/size/w600/2019/06/transfer_learning_tutorial_room-4.jpgg 600w,
                          ../content/images/size/w1000/2019/06/transfer_learning_tutorial_room-4.jpg 1000w,
                         ../content/images/size/w2000/2019/06/transfer_learning_tutorial_room-4.jpg 2000w"
                    sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px"
                    src="../content/images/size/w2000/2019/06/transfer_learning_tutorial_room-4.jpg"
                    alt="NAACL 2019 Highlights"
                />
            </figure>

            <section class="post-full-content">
                <div class="post-content">
                    <p>This post discusses highlights of the 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<a href="https://naacl2019.org/">NAACL 2019</a>).</p><p>You can find past highlights of conferences <a href="http://ruder.io/tag/events/">here</a>. The conference accepted 424 papers (which you can find <a href="https://www.aclweb.org/anthology/events/naacl-2019/#n19-1">here</a>) and had 1575 participants (see the <a href="https://naacl2019.org/downloads/naacl2019-intro-slides.pdf">opening session slides</a> for more details). These are the topics that stuck out for me most:</p><ul><li><a href="index.html#transfer-learning">Transfer learning</a></li><li><a href="index.html#common-sense-reasoning">Common sense reasoning</a></li><li><a href="index.html#natural-language-generation">Natural language generation</a></li><li><a href="index.html#bias">Bias</a></li><li><a href="index.html#non-english-languages">Non-English languages</a></li><li><a href="index.html#diversity-and-inclusion">Diversity and inclusion</a></li></ul><h2 id="transfer-learning">Transfer learning</h2><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://ruder.io/content/images/2019/06/transfer_learning_tutorial_room_2.jpg" class="kg-image"><figcaption>The room at the Transfer Learning in NLP tutorial (Image credit: <a href="https://twitter.com/soldni/status/1135269017512546304">Luca Soldaini</a>)</figcaption></figure><p>Interest in transfer learning remains high. The <a href="https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit?usp=sharing">Transfer Learning in NLP</a> tutorial (pictured above and organized by <a href="https://scholar.google.com/citations?user=K5nCPZwAAAAJ&amp;hl=en">Matthew Peters</a>, <a href="https://www.cs.cmu.edu/~sswayamd/">Swabha Swayamdipta</a>, <a href="http://thomwolf.io/">Thomas Wolf</a>, and me) was packed. NAACL 2019 awarded the best long paper award to <a href="https://www.aclweb.org/anthology/N19-1423">BERT</a>, arguably the most impactful recent transfer learning method. Despite its recency, conference papers already leveraged BERT for <a href="https://www.aclweb.org/anthology/N19-1035">aspect-based sentiment analysis</a>, <a href="https://www.aclweb.org/anthology/N19-1242">review reading comprehension</a>, <a href="https://www.aclweb.org/anthology/N19-1421">common sense reasoning</a>, and <a href="https://www.aclweb.org/anthology/N19-4013">open-domain question answering</a>. </p><p>At the <a href="https://repeval2019.github.io/">RepEval</a> workshop, Kristina Toutanova discussed how to <a href="https://arxiv.org/abs/1906.00300">use transfer learning for open-domain question answering</a>. With appropriate pretraining using an Inverse Cloze Task, the retriever and reader can be fine-tuned directly on QA pairs without an intermediate IR system. This demonstrates that <strong>a careful initialization + fine-tuning</strong> are two key ingredients for transfer learning and work even on challenging tasks. This has also been shown in the past for <a href="https://www.aclweb.org/anthology/P18-1073">learning cross-lingual word embeddings</a> and <a href="https://arxiv.org/abs/1804.07755">unsupervised MT</a>. She also made the point that <strong>single-vector sentence/paragraph representations are very useful for retrieval</strong>—and that we should continue to work on them. Overall, there are many exciting research directions in transfer learning in NLP, some of which we outlined at <a href="https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit#slide=id.g5882add69e_5_673">the end of our tutorial</a>. My other highlights include: </p><ul><li><strong>Single-step Auxiliary loss Transfer Learning</strong> (SiATL; <a href="https://www.aclweb.org/anthology/N19-1213">Chronopoulou et al.</a>), an "embarrassingly simple" approach that reduces some of the complexity of <a href="https://arxiv.org/abs/1801.06146">ULMFiT</a> via multi-task learning and exponentially decaying the auxiliary loss.</li><li><strong>AutoSeM</strong> (<a href="https://www.aclweb.org/anthology/N19-1355">Guo et al</a>.), a two-stage pipeline for multi-task learning that utilizes multi-armed bandits and Bayesian optimization to learn the best auxiliary task and the best task mixing ratio respectively.</li><li>An <strong>evaluation of contextual representation across 16 tasks</strong> (<a href="https://www.aclweb.org/anthology/N19-1112">Liu et al.</a>) that shows that they are bad at capturing fine-grained linguistic knowledge and higher layers in RNNs are more task-specific than in Transformers.</li></ul><h2 id="common-sense-reasoning">Common sense reasoning</h2><p>Language modelling is a pretraining task that has been shown to learn generally useful representations at scale. However, there are some things that are simply never written, even in billions of tokens.<strong> Overcoming this reporting bias is a key challenge</strong> in adapting language models to more complex tasks. To test reasoning with knowledge that is often left unsaid, the <a href="https://www.aclweb.org/anthology/N19-1421">best resource paper</a> used the common sense knowledge base ConceptNet as “seed”. They created <a href="https://www.tau-nlp.org/commonsenseqa">CommonsenseQA</a>, a dataset of multiple-choice questions where most answers have the same relation to the target concept (see below).</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://ruder.io/content/images/2019/06/commonsenseqa_examples.png" class="kg-image"><figcaption>Example question-answer pairs in CommonsenseQA (Source: <a href="https://www.aclweb.org/anthology/N19-1421">Talmor et al.</a>)</figcaption></figure><p>This requires the model to use common sense rather than just relational or co-occurrence information to answer the question. BERT achieves 55.9% accuracy on this dataset—and is estimated to achieve around 75% with 100k examples—still well below human performance 88.9%. What does it take to get to those 88.9%? Most likely <a href="https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit#slide=id.g5888218f39_11_238"><strong>structured knowledge, interactive and multimodal learning</strong></a>. In his talk at the <a href="https://sites.google.com/view/sivl2019/home">Workshop on Shortcomings in Vision and Language</a> (SiLV), Yoav Artzi discussed <a href="https://yoavartzi.com/slides/2019_06_06_sivl_naacl.pdf">language diversity in grounded NLU</a>, noting that we need to move from synthetic to more realistic images for learning grounded representations.</p><p>Another prerequisite for natural language understanding is compositional reasoning. The <a href="https://nlitutorial.github.io/">Deep Learning for Natural Language Inference tutorial</a> discussed natural language inference, a common benchmark for evaluating such forms of reasoning in-depth. I particularly liked the following papers:</p><ul><li><strong>A label consistency framework for procedural text comprehension</strong> (<a href="https://www.aclweb.org/anthology/N19-1244">Du et al.</a>) that encourages consistency between predictions from descriptions of the same process. This is a clever way to use intuition and additional data to incorporate an inductive bias into the model.</li><li><strong>Discrete Reasoning Over the content of Paragraphs</strong> (DROP; <a href="https://www.aclweb.org/anthology/N19-1246">Dua et al.</a>), which requires models to resolve references in a question and perform discrete operations (e.g. addition, counting, sorting) over multiple referents in the text.</li></ul><h2 id="natural-language-generation">Natural language generation</h2><p>At the <a href="https://neuralgen.io/">NeuralGen</a> workshop, Graham Neubig <a href="http://www.phontron.com/slides/neubig19neuralgen.pdf">discussed methods to optimize a non-differentiable objective function</a> such as BLEU directly, including minimum risk training and REINFORCE and tricks to deal with their instability and get them to work. While we had touched on <a href="https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit#slide=id.g512941aa9e_0_36">transfer learning for natural language generation</a> (NLG) in our tutorial, Sasha Rush provided many more details and <a href="http://nlp.seas.harvard.edu/slides/Pre-training%20for%20Generation.pdf">discussed different methods of using language models</a> to improve NLG quality. Another way to improve sample quality is to focus on decoding. Yejin Choi discussed a <a href="https://arxiv.org/abs/1904.09751">new sampling method</a> that samples from the head of the distribution and leads to better text quality. She also discussed the generation of fake news and how large pretrained language models such as <a href="https://arxiv.org/abs/1905.12616">Grover</a> can be used to defend against them. </p><p>Generative adversarial networks (GANs) are a popular way to generate images, but so far have underperformed for language. The <a href="https://drive.google.com/drive/folders/1E4uHe4_TD4yDJws3t1kXJQanUFJiqpBB">Deep Adversarial Learning for NLP tutorial</a> argued that we should not give up on them as the <strong>unsupervised or self-supervised learning done by GANs has many applications in NLP</strong>.</p><p>Another compelling aspect of generation is to enable multiple agents to communicate effectively. Besides providing a window into how language emerges, it may be necessary for interactive learning and to transfer knowledge among agents. Angeliki Lazaridou discussed in her SiLV workshop talk that deep reinforcement learning tools seem to work well for this setting but argued that <strong>better biases are needed</strong>. In addition, it is still <strong>difficult to <a href="https://arxiv.org/abs/1612.07182">interface emergent language to natural language</a></strong>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://ruder.io/content/images/2019/06/huse_trade-offs.png" class="kg-image"><figcaption>Trade-offs between quality and diversity of different models (circles) on NLG tasks (Image credit: <a href="https://www.aclweb.org/anthology/N19-1169">Hashimoto et al.</a>)</figcaption></figure><p>I also enjoyed the following papers:</p><ul><li><strong>Human Unified with Statistical Evaluation</strong> (HUSE; <a href="https://www.aclweb.org/anthology/N19-1169">Hashimoto et al.</a>), a new metric for natural language generation that can consider both diversity and quality and yields a Pareto frontier by trading off one of the two (see above). Methods such as temperature annealing result in higher quality, but reduce diversity.</li><li><strong>Separating planning from realization</strong> (<a href="https://arxiv.org/abs/1904.03396">Moryossef et al.</a>) can improve the quality of generated text from structured data such as RDF triplets as there are often multiple ways structured information can be realized in text.</li><li><strong>Decoupling syntax and surface form generation</strong> (<a href="https://arxiv.org/abs/1804.07707">Cao &amp; Clark</a>) is another way to deal with the underspecified problem of text generation from structured data (in this case, abstract meaning representations). </li><li><strong>A systematic analysis that probes how useful the visual modality actually is for multimodal translation</strong> (<a href="https://www.aclweb.org/anthology/N19-1422">Caglayan et al.</a>) and was awarded the best short paper award. It observes that models with less textual information more strongly rely on the visual context, contrary to current beliefs.</li></ul><h2 id="bias">Bias</h2><p>The <a href="https://naacl2019.org/calls/papers/#theme-topics">theme of the conference</a> was model bias. The diverse sets of keynotes fit very well into this theme. The first keynote by <a href="http://randomwalker.info/">Arvind Narayanan</a> in particular highlighted one under-appreciated aspect of bias, i.e. that we can <strong>leverage the bias in our models to improve our understanding of human culture</strong>.</p><p>On the whole, there is a <strong>fine line between desirable and undesirable bias</strong>. We often try to encode inductive bias about how the world works, such as <a href="http://ruder.io/emnlp-2018-highlights/index.html#inductive-bias">objects being invariant to translation</a>. On the other hand, we do not want our models to learn superficial cues or relations that are not part of our possibly idealized perception of the world, such as <a href="https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf">gender bias</a>. Ultimately, super-human performance should not just entail that models outperform humans quantitively but also that they are less biased and fallible.</p><p>Lastly, we should be conscious that <strong>technology has lasting impact in the real world</strong>. As one vivid example of this, <a href="https://textio.com/team/">Kieran Snyder</a> recounted in her keynote the time when she had to design a sorting algorithm for <a href="https://en.wikipedia.org/wiki/Sinhala_language">Sinhala</a> (see below). Sorting Sinhalese names was necessary for the Sri Lankan government to be able to search for survivors in the aftermath of the 2004 tsunami. Her decision on how to alphabetize the language later became part of an official government policy.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://ruder.io/content/images/2019/06/sinhala_vowels.jpg" class="kg-image"><figcaption>Vowels in Sinhala (Image credit: <a href="https://www.omniglot.com/writing/sinhala.htm">Omniglot</a>)</figcaption></figure><p>Some of my favourite papers on bias include:</p><ul><li><strong>Debiasing methods only superficially remove bias in word embeddings </strong>(<a href="https://www.aclweb.org/anthology/N19-1061">Gonen &amp; Goldberg</a>); bias is still reflected in—and can be recovered from—the distances in the debiased embeddings.</li><li><strong>An evaluation of bias in contextualized word embeddings</strong> (<a href="https://www.aclweb.org/anthology/N19-1064">Zhao et al.</a>) finds that ELMo syntactically and unequally encodes gender information and—more importantly—that this bias is inherited by downstream models, such as a coreference system. </li></ul><h2 id="non-english-languages">Non-English languages</h2><p>On the topic of different languages, during the conference, the <a href="https://twitter.com/emilymbender/status/1135691925674217473">“Bender Rule”</a>—named after <a href="https://faculty.washington.edu/ebender/">Emily Bender</a> who is known for her advocacy for multilingual language processing, among other things—was <a href="https://twitter.com/EvpokPadding/status/1136649868800352262">frequently</a> <a href="https://twitter.com/amitmoryossef/status/1136359765758697478">invoked</a> <a href="https://twitter.com/adinamwilliams/status/1136313903988822016">after</a> <a href="https://twitter.com/EmmaSManning/status/1136395448313401346">presentations</a>. In short, the rule states: "<strong>Always name the language(s) you are working on.</strong>" Not explicitly identifying the language under consideration leads to English being perceived as the default and as proxy for other languages, which is problematic in many ways (see <a href="http://faculty.washington.edu/ebender/papers/Bender-SDSS-2019.pdf">Emily's slides</a> for a thorough rationale).</p><p>In this vein, some of my favourite papers from the conference investigate how the performance of our models changes as we apply them other languages:</p><ul><li><strong>Polyglot contextual representations </strong>(<a href="https://www.aclweb.org/anthology/N19-1392">Mulcaire et al.</a>) that are trained on English and an additional language by initializing word embeddings with cross-lingual representations. For some settings (Chinese SRL, Arabic NER), cross-lingual training yields large improvements.</li><li><strong>A study on transfer of dependency parsers trained on English to 30 other languages </strong>(<a href="https://www.aclweb.org/anthology/N19-1253">Ahmad et al.</a>) finds that RNNs trained on English transfer well to languages close to English, but self-attention models transfer better to distant languages.</li><li><strong>An unsupervised POS tagger for low-resource languages</strong> (<a href="https://www.aclweb.org/anthology/N19-1252">Cardenas et al.</a>) that "deciphers" Brown cluster ids in order to generate the POS sequence and achieves state-of-the-art performance on Sinhalese (see above).</li></ul><h2 id="diversity-and-inclusion">Diversity and inclusion</h2><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://ruder.io/content/images/2019/06/badge_stickers.jpg" class="kg-image"><figcaption>Badge stickers at NAACL 2019 (Image credit: <a href="https://twitter.com/natschluter/status/1135963599216750593">Natalie Schluter</a>)</figcaption></figure><p>As the community is growing it is important that new members feel included and that their voices are heard. NAACL 2019 put into effect a wide range of initiatives in this regard, from thoughtful touches such as badge stickers (see above) to matching newcomers with mentors and “big siblings”, to fundamental ones such as childcare (see below) and <a href="https://naacl2019.org/captions/">live captions</a>. I particularly appreciated the <a href="https://twitter.com/NAACLHLT/status/1134181082151227393">live tweeting</a>, which made the conference accessible to people who could not attend.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://ruder.io/content/images/2019/06/childcare_room-1.jpg" class="kg-image"><figcaption>Childcare room at NAACL 2019 (Image credit: <a href="https://twitter.com/KieranSnyder/status/1135924564771450880">Kieran Snyder</a>)</figcaption></figure><p><em>Cover image: The room at the <a href="https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit?usp=sharing">Transfer Learning in NLP</a> tutorial (Image credit: <a href="https://twitter.com/thedansimonson/status/1135275735730597889">Dan Simonson</a>)</em></p>
                </div>
            </section>



        </article>

    </div>
</main>

<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
                <article class="read-next-card">
                    <header class="read-next-card-header">
                        <h3><span>More in</span> <a href="../tag/events/index.html">events</a></h3>
                    </header>
                    <div class="read-next-card-content">
                        <ul>
                            <li>
                                <h4><a href="../state-of-transfer-learning-in-nlp/index.html">The State of Transfer Learning in NLP</a></h4>
                                <div class="read-next-card-meta">
                                    <p><time datetime="2019-08-18">18 Aug 2019</time> –
                                        15 min read</p>
                                </div>
                            </li>
                            <li>
                                <h4><a href="../eurnlp/index.html">EurNLP</a></h4>
                                <div class="read-next-card-meta">
                                    <p><time datetime="2019-07-04">4 Jul 2019</time> –
                                        2 min read</p>
                                </div>
                            </li>
                            <li>
                                <h4><a href="../aaai-2019-highlights/index.html">AAAI 2019 Highlights: Dialogue, reproducibility, and more</a></h4>
                                <div class="read-next-card-meta">
                                    <p><time datetime="2019-02-07">7 Feb 2019</time> –
                                        11 min read</p>
                                </div>
                            </li>
                        </ul>
                    </div>
                    <footer class="read-next-card-footer">
                        <a href="../tag/events/index.html">See all 11 posts
                            →</a>
                    </footer>
                </article>

                <article class="post-card post tag-events tag-natural-language-processing ">

    <a class="post-card-image-link" href="../eurnlp/index.html">
        <img class="post-card-image"
            srcset="../content/images/size/w300/2019/07/EurNLP-ban_2.jpg 300w,
                   ../content/images/size/w600/2019/07/EurNLP-ban_2.jpgg 600w,
                  ../content/images/size/w1000/2019/07/EurNLP-ban_2.jpg 1000w,
                 ../content/images/size/w2000/2019/07/EurNLP-ban_2.jpg 2000w"
            sizes="(max-width: 1000px) 400px, 700px"
            src="../content/images/size/w600/2019/07/EurNLP-ban_2.jpg"
            alt="EurNLP"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../eurnlp/index.html">

            <header class="post-card-header">
                    <div class="post-card-primary-tag">events</div>
                <h2 class="post-card-title">EurNLP</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>The first European NLP Summit (EurNLP) will take place in London on October 11, 2019. It is an opportunity to foster discussion and collaboration between researchers in and around Europe.</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>
            
                    <a href="../author/sebastian/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../content/images/size/w100/2019/02/new_profile_photo_square-1.jpg" alt="Sebastian Ruder" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/sebastian/index.html">Sebastian Ruder</a></span>
                <span class="post-card-byline-date"><time datetime="2019-07-04">4 Jul 2019</time> <span class="bull">&bull;</span> 2 min read</span>
            </div>
        </footer>

    </div>

</article>

                <article class="post-card post tag-transfer-learning tag-natural-language-processing tag-multi-task-learning tag-domain-adaptation tag-cross-lingual ">

    <a class="post-card-image-link" href="../thesis/index.html">
        <img class="post-card-image"
            srcset="../content/images/size/w300/2019/03/transfer_learning_taxonomy-1.png 300w,
                   ../content/images/size/w600/2019/03/transfer_learning_taxonomy-1.png 600w,
                  ../content/images/size/w1000/2019/03/transfer_learning_taxonomy-1.png 1000w,
                 ../content/images/size/w2000/2019/03/transfer_learning_taxonomy-1.png 2000w"
            sizes="(max-width: 1000px) 400px, 700px"
            src="../content/images/size/w600/2019/03/transfer_learning_taxonomy-1.png"
            alt="Neural Transfer Learning for Natural Language Processing (PhD thesis)"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../thesis/index.html">

            <header class="post-card-header">
                    <div class="post-card-primary-tag">transfer learning</div>
                <h2 class="post-card-title">Neural Transfer Learning for Natural Language Processing (PhD thesis)</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>This post discusses my PhD thesis Neural Transfer Learning for Natural Language Processing and some new material presented in it.</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Sebastian Ruder
                    </div>
            
                    <a href="../author/sebastian/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../content/images/size/w100/2019/02/new_profile_photo_square-1.jpg" alt="Sebastian Ruder" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/sebastian/index.html">Sebastian Ruder</a></span>
                <span class="post-card-byline-date"><time datetime="2019-03-23">23 Mar 2019</time> <span class="bull">&bull;</span> 1 min read</span>
            </div>
        </footer>

    </div>

</article>
        </div>
    </div>
</aside>




        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://ruder.io">Sebastian Ruder</a> &copy; 2020</section>
                <nav class="site-footer-nav">
                    <a href="https://ruder.io">Latest Posts</a>
                    
                    <a href="https://twitter.com/seb_ruder" target="_blank" rel="noopener">Twitter</a>
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>


    <script
        src="https://code.jquery.com/jquery-3.4.1.min.js"
        integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
        crossorigin="anonymous">
    </script>
    <script src="../assets/built/casper.js?v=8587ecf4f6"></script>

    <script>
        // Parse the URL parameter
        function getParameterByName(name, url) {
            if (!url) url = window.location.href;
            name = name.replace(/[\[\]]/g, "\\$&");
            var regex = new RegExp("[?&]" + name + "(=([^&#]*)|&|#|$)"),
                results = regex.exec(url);
            if (!results) return null;
            if (!results[2]) return '';
            return decodeURIComponent(results[2].replace(/\+/g, " "));
        }

        // Give the parameter a variable name
        var action = getParameterByName('action');

        $(document).ready(function () {
            if (action == 'subscribe') {
                $('body').addClass("subscribe-success");
            }

            $('.subscribe-success-message .subscribe-close').click(function () {
                $('.subscribe-success-message').addClass('close');
            });

            // Reset form on opening subscrion overlay
            $('.subscribe-button').click(function() {
                $('.subscribe-overlay form').removeClass();
                $('.subscribe-email').val('');
            });
        });
    </script>

    <script>
    $(document).ready(function () {
        // FitVids - start
        var $postContent = $(".post-full-content");
        $postContent.fitVids();
        // FitVids - end

        // Replace nav with title on scroll - start
        Casper.stickyNavTitle({
            navSelector: '.site-nav-main',
            titleSelector: '.post-full-title',
            activeClass: 'nav-post-title-active'
        });
        // Replace nav with title on scroll - end

        // Hover on avatar
        var hoverTimeout;
        $('.author-list-item').hover(function () {
            var $this = $(this);

            clearTimeout(hoverTimeout);

            $('.author-card').removeClass('hovered');
            $(this).children('.author-card').addClass('hovered');

        }, function () {
            var $this = $(this);

            hoverTimeout = setTimeout(function () {
                $this.children('.author-card').removeClass('hovered');
            }, 800);
        });
    });
</script>


    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.1.6/zepto.min.js"></script>
<script>jQuery = Zepto</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/plugins/line-numbers/prism-line-numbers.min.js"></script>
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism.min.css" />
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/plugins/line-numbers/prism-line-numbers.min.css" />
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism-coy.min.css" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-python.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-60512592-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-60512592-1');
</script>

</body>
</html>
